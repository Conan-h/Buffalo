main start at this time 1713742533.8946028
-----------------------------------------before load data 
 Nvidia-smi: 0.80816650390625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

success----------------------------------------
# Nodes: 111059956
# Edges: 1615685872
# Train: 1207179
# Val: 125265
# Test: 109727512
# Classes: 172

----------------------------------------start of run function 
 Nvidia-smi: 0.80816650390625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5546061992645264
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0029201507568359375
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.03694009780883789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5577824115753174
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.158512115478516
self.buckets_partition() spend  sec:  2.5947506427764893
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 2.34271240234375 GB
    Memory Allocated: 1.1128325462341309  GigaBytes
Max Memory Allocated: 1.1128325462341309  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 41.45989990234375 GB
    Memory Allocated: 36.76131296157837  GigaBytes
Max Memory Allocated: 39.16768026351929  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 42.45989990234375 GB
    Memory Allocated: 37.76131296157837  GigaBytes
Max Memory Allocated: 39.16768026351929  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 42.45989990234375 GB
    Memory Allocated: 36.75373554229736  GigaBytes
Max Memory Allocated: 39.16768026351929  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 42.45989990234375 GB
    Memory Allocated: 36.753501892089844  GigaBytes
Max Memory Allocated: 39.16768026351929  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 42.45989990234375 GB
    Memory Allocated: 38.00344371795654  GigaBytes
Max Memory Allocated: 39.16768026351929  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 61.06927490234375 GB
    Memory Allocated: 57.03606986999512  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 61.06927490234375 GB
    Memory Allocated: 57.218461990356445  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 61.06927490234375 GB
    Memory Allocated: 57.03347873687744  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 61.06927490234375 GB
    Memory Allocated: 57.03347873687744  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 61.06927490234375 GB
    Memory Allocated: 57.215871810913086  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 63.47943115234375 GB
    Memory Allocated: 1.3029470443725586  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 48.07904052734375 GB
    Memory Allocated: 39.67725610733032  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 48.96185302734375 GB
    Memory Allocated: 40.55892610549927  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 48.96185302734375 GB
    Memory Allocated: 39.67036771774292  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 48.96185302734375 GB
    Memory Allocated: 39.67036771774292  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 48.96185302734375 GB
    Memory Allocated: 40.7724552154541  GigaBytes
Max Memory Allocated: 58.60339403152466  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 66.52044677734375 GB
    Memory Allocated: 61.83837604522705  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 66.52044677734375 GB
    Memory Allocated: 61.8961615562439  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 66.52044677734375 GB
    Memory Allocated: 61.837703704833984  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 66.52044677734375 GB
    Memory Allocated: 61.655311584472656  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 66.52044677734375 GB
    Memory Allocated: 61.71309757232666  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 67.90325927734375 GB
    Memory Allocated: 1.205878734588623  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 67.90716552734375 GB
    Memory Allocated: 39.032341957092285  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 67.90716552734375 GB
    Memory Allocated: 39.89866542816162  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 67.90716552734375 GB
    Memory Allocated: 39.02557373046875  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 67.90716552734375 GB
    Memory Allocated: 39.02557373046875  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 67.90716552734375 GB
    Memory Allocated: 40.10847806930542  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 61.115318298339844  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 61.16556739807129  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 61.11473369598389  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 61.05694818496704  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 61.107197761535645  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 1.2390666007995605  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 39.29445457458496  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 40.170287132263184  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 39.287611961364746  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 39.287611961364746  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 40.3824028968811  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 61.23342990875244  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 61.290905475616455  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 61.23276138305664  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 61.182512283325195  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 61.23998832702637  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 1.2721748352050781  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 38.707661628723145  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 39.569878578186035  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 38.70092535018921  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 38.70092535018921  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 39.77869653701782  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 60.43857288360596  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 60.491979122161865  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 60.43795156478882  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 60.380475997924805  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 60.43388271331787  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.53021240234375 GB
    Memory Allocated: 1.3130245208740234  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 38.6679573059082  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 39.53184795379639  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 38.661208152770996  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 38.661208152770996  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 39.741071701049805  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 60.25610113143921  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 60.3102331161499  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 60.25547122955322  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 60.202064990997314  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 60.256197452545166  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 1.3006978034973145  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 37.06970691680908  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 37.874732971191406  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 37.06310558319092  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 37.06310558319092  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 38.0693883895874  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 57.96273326873779  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 57.999404430389404  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 57.9623064994812  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 57.90817451477051  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 57.94484615325928  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 1.4081077575683594  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 38.28707218170166  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 39.2350492477417  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 38.27966594696045  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 38.27966594696045  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.53216552734375 GB
    Memory Allocated: 39.4646372795105  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.66107177734375 GB
    Memory Allocated: 59.33789014816284  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.66107177734375 GB
    Memory Allocated: 59.458693981170654  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.66107177734375 GB
    Memory Allocated: 59.33689260482788  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.66107177734375 GB
    Memory Allocated: 59.29977321624756  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.66107177734375 GB
    Memory Allocated: 59.42012929916382  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

number of input  16977747
----------------------------------------after optimizer
 Nvidia-smi: 78.94036865234375 GB
    Memory Allocated: 1.5604033470153809  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 4.093122482299805
pure train time :  5.541337966918945
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.561464309692383
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.003016948699951172
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.03311920166015625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5648860931396484
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.104330778121948
self.buckets_partition() spend  sec:  2.5980334281921387
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94036865234375 GB
    Memory Allocated: 1.29439115524292  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 36.949970722198486  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 37.94982957839966  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 36.9421591758728  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 36.9421591758728  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 38.19198274612427  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 57.21295642852783  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 57.39534854888916  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 57.21069097518921  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 57.09033536911011  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 57.237549781799316  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 1.3084392547607422  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 39.64296340942383  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 40.523295402526855  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 39.636085510253906  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 39.636085510253906  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 40.73650074005127  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 61.80116939544678  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 61.85895490646362  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 61.80036735534668  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 61.61810493469238  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 61.67602062225342  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 1.2133092880249023  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 39.01191568374634  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 39.87688493728638  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 39.00515794754028  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 39.00515794754028  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 40.08636951446533  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 61.091487407684326  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 61.14173650741577  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 61.09090280532837  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 61.03298759460449  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 61.083237171173096  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94427490234375 GB
    Memory Allocated: 1.2456793785095215  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 39.325841426849365  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 40.20296049118042  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 39.31898880004883  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 39.31898880004883  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 40.41538763046265  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 61.265498638153076  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 61.32297420501709  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 61.264830112457275  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 61.21458101272583  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 61.272057056427  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 1.2811193466186523  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 38.778438091278076  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 39.64183473587036  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 38.771692752838135  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 38.771692752838135  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 39.85093879699707  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 60.524972438812256  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 60.578378677368164  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 60.52435111999512  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 60.4668755531311  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 60.52028226852417  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 1.3174519538879395  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 38.67419195175171  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 39.53718709945679  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 38.66744947433472  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 38.66744947433472  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 39.746193408966064  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 60.26218271255493  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 60.316314697265625  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 60.261552810668945  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 60.20814657211304  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 60.26227903366089  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 1.3102288246154785  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 37.0423059463501  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 37.846248626708984  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 37.036025047302246  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 37.036025047302246  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 38.040953636169434  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 57.933340072631836  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 57.97001123428345  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 57.932913303375244  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 57.87878131866455  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 57.91545295715332  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94622802734375 GB
    Memory Allocated: 1.4189133644104004  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.376678466796875  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.32638359069824  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.369258880615234  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.369258880615234  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.55639028549194  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 59.414751052856445  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 59.534626483917236  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 59.41329765319824  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 59.37662649154663  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 59.49650239944458  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

number of input  16980220
----------------------------------------after optimizer
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.5650739669799805  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.7524425983428955
pure train time :  3.1937355995178223
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.8297462463378906
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0031807422637939453
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.04558897018432617
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.833120584487915
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.544346332550049
self.buckets_partition() spend  sec:  2.878763198852539
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.28965425491333  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 36.86223268508911  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 37.860862255096436  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 36.85400152206421  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 36.85400152206421  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.10228872299194  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.12246561050415  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.30485773086548  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.12012052536011  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.000245094299316  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.147379875183105  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.3047881126403809  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.6172308921814  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 40.49777364730835  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.6103515625  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.6103515625  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 40.71103000640869  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.78038454055786  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.83817005157471  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.779202938079834  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.59732007980347  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.65561532974243  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.2108993530273438  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.02596426010132  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.891995906829834  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.019197940826416  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.019197940826416  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 40.10173749923706  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.10787010192871  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.158119201660156  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.107285499572754  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.04899072647095  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.09924030303955  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.2462315559387207  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.36252546310425  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 40.24096059799194  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.35566234588623  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.35566234588623  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 40.45370626449585  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.30332136154175  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.36079692840576  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.30265283584595  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.2524037361145  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.309879779815674  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.2792510986328125  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.71451759338379  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.57660961151123  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.70778226852417  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.70778226852417  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.78539752960205  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.45035409927368  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.50376033782959  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.44973278045654  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.39225721359253  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.445663928985596  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.3180084228515625  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.720186710357666  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.58360052108765  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.713440895080566  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.713440895080566  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.79270839691162  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.30880260467529  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.362934589385986  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.30817270278931  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.2547664642334  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.30889892578125  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.3104701042175293  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 37.11138153076172  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 37.916948318481445  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 37.104780197143555  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 37.104780197143555  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.11173868179321  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 58.00131320953369  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 58.0379843711853  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 58.0008864402771  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.946754455566406  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.983426094055176  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.4180335998535156  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.36758852005005  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.3159384727478  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.36017942428589  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.36017942428589  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.54561710357666  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 59.40373134613037  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 59.52360677719116  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 59.402273178100586  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 59.365602016448975  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 59.485477924346924  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

number of input  16978063
----------------------------------------after optimizer
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.56378173828125  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.5538530349731445
pure train time :  3.1482372283935547
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.7625651359558105
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.002798795700073242
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.05623769760131836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.765643358230591
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.701777458190918
self.buckets_partition() spend  sec:  2.821932077407837
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.2927603721618652  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 36.96159887313843  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 37.9616322517395  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 36.95378589630127  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 36.95378589630127  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.20382785797119  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.22303533554077  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.4054274559021  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.22064447402954  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.10076904296875  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.24830198287964  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.3081674575805664  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.68748712539673  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 40.569303035736084  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.68059778213501  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.68059778213501  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 40.78286790847778  GigaBytes
Max Memory Allocated: 63.830552101135254  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.84840536117554  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.90619087219238  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.84757423400879  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.66534090042114  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.72328567504883  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.210662841796875  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.05250883102417  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.91821908950806  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.04574537277222  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.04574537277222  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 40.127883434295654  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.134583473205566  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.18483257293701  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.13399887084961  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.07605457305908  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.126304149627686  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.2430381774902344  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.25927114486694  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 40.13483476638794  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.25243043899536  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.25243043899536  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 40.346885204315186  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.19706153869629  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.2545371055603  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.19639301300049  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.14614391326904  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 61.203619956970215  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.2803735733032227  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.75881624221802  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.62104654312134  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.75207996368408  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.75207996368408  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.82986783981323  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.49480628967285  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.54821252822876  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.49418497085571  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.4367094039917  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.490116119384766  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.314091682434082  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.59265947341919  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.45384168624878  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.58593130111694  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.58593130111694  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.66240930557251  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.182570934295654  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.23670291900635  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.18194103240967  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.12853479385376  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 60.18266725540161  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.3119664192199707  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 37.069270610809326  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 37.87511205673218  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 37.06297492980957  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 37.06297492980957  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.070276737213135  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.96067714691162  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.99734830856323  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.96025037765503  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.906118392944336  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 57.942790031433105  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 1.4187617301940918  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.35050058364868  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.300190448760986  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.34308099746704  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 38.34308099746704  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.94818115234375 GB
    Memory Allocated: 39.53019332885742  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.38755750656128  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.50823736190796  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.38689613342285  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.34942054748535  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.47010087966919  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

number of input  16975147
----------------------------------------after optimizer
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.564073085784912  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.369375228881836
pure train time :  3.1265742778778076
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.6988179683685303
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0025987625122070312
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.04431295394897461
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.701571226119995
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.457207202911377
self.buckets_partition() spend  sec:  2.7459213733673096
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.287285327911377  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.850839614868164  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.84886646270752  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.84304237365723  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.84304237365723  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.090576171875  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.11011457443237  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.2925066947937  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.10772371292114  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 56.98784828186035  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.134960651397705  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.3115110397338867  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.666869163513184  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.54790019989014  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.65998601913452  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.65998601913452  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.76127481460571  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.82728958129883  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.885075092315674  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.826369285583496  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.644225120544434  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.7022590637207  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.209909439086914  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.93952560424805  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.80392074584961  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.932772159576416  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.932772159576416  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.01326608657837  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.02015542984009  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.07040452957153  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.01957082748413  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.96153736114502  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.01178693771362  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2502217292785645  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.401522159576416  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.28017282485962  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.394657611846924  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.394657611846924  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.49297094345093  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.343936920166016  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.40141248703003  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.343268394470215  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.29301929473877  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.35049533843994  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2874493598937988  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.862385272979736  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.72744417190552  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.855626583099365  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.855626583099365  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.93695020675659  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.611817836761475  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.66522407531738  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.611196517944336  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.55372095108032  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.60712766647339  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.317643642425537  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.64007902145386  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.502002239227295  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.63334512710571  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.63334512710571  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.71074914932251  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.2254524230957  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.2795844078064  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.22482252120972  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.17141628265381  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.22554874420166  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.3158321380615234  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.13444709777832  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.94053554534912  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.127845764160156  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.127845764160156  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.135456562042236  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 58.01664352416992  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 58.05331468582153  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 58.01621675491333  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.96208477020264  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.998756408691406  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.4229345321655273  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.39126634597778  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.340495586395264  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.38385009765625  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.38385009765625  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.57038688659668  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.42819023132324  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.54806566238403  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.42674446105957  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.39007329940796  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.50994920730591  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

number of input  16976497
----------------------------------------after optimizer
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.568812370300293  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0986175537109375
pure train time :  3.1485891342163086
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  3.446249485015869
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0023050308227539062
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.029428958892822266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  3.4487433433532715
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.243102788925171
self.buckets_partition() spend  sec:  3.4782121181488037
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2917990684509277  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.93407583236694  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.93348169326782  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.92626762390137  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.92626762390137  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.175525188446045  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.19547986984253  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.37787199020386  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.1930890083313  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.07321357727051  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.21979808807373  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.3093414306640625  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.67897653579712  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.560768604278564  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.6720871925354  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.6720871925354  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.77432727813721  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.84083032608032  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.89861583709717  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.839969635009766  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.65776586532593  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.71574020385742  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.211510181427002  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.96931600570679  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.834171772003174  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.96255922317505  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.96255922317505  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.04362916946411  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.05468940734863  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.10493850708008  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.054104804992676  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.99613094329834  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.04638051986694  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2467260360717773  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.30494165420532  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.180583477020264  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.29810047149658  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.29810047149658  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.39265298843384  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.24247694015503  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.29995250701904  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.24180841445923  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.19155931472778  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.249035358428955  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2864995002746582  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.79901456832886  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.66264772415161  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.79226732254028  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.79226732254028  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.871809005737305  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.53902196884155  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.59242820739746  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.538400650024414  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.4809250831604  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.53433179855347  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.315786361694336  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.61655330657959  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.478830337524414  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.609816551208496  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.609816551208496  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.687663078308105  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.206576347351074  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.26070833206177  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.20594644546509  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.15254020690918  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.20667266845703  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.3168702125549316  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.15021562576294  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.956836223602295  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.143614292144775  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.143614292144775  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.15189027786255  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 58.03463172912598  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 58.07130289077759  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 58.034204959869385  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.98007297515869  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 58.01674461364746  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.4160637855529785  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.29436111450195  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.24229335784912  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.2869553565979  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.2869553565979  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.47187089920044  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.3301796913147  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.45005512237549  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.32868719100952  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.29201602935791  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.41189193725586  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

number of input  16970006
----------------------------------------after optimizer
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.5623655319213867  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.8633289337158203
pure train time :  3.1433703899383545
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  3.246699810028076
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.001552581787109375
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.03087925910949707
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  3.2488772869110107
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.934696674346924
self.buckets_partition() spend  sec:  3.2797956466674805
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2944092750549316  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.98135805130005  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.981529712677  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.973544120788574  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.973544120788574  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.223758697509766  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.2425971031189  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.424989223480225  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.240469455718994  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.1205940246582  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.267523765563965  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.3094744682312012  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.63930797576904  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.521209716796875  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.63241767883301  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.63241767883301  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.73479509353638  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.80456876754761  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.86235427856445  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.80335092544556  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.62150430679321  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.6798357963562  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2128801345825195  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.01109600067139  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.87681293487549  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.004332542419434  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.004332542419434  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.08647871017456  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.096096992492676  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.14634609222412  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.09551239013672  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.03718137741089  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.08743095397949  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2467575073242188  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.36135768890381  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.23871421813965  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.35450315475464  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.35450315475464  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.45119905471802  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.30186605453491  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.359341621398926  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.30119752883911  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.250948429107666  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.30842447280884  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2784719467163086  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.75228309631348  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.61455154418945  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.74554634094238  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.74554634094238  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.82338190078735  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.48483848571777  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.53824472427368  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.484217166900635  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.42674160003662  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.48014831542969  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.3134346008300781  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.60945749282837  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.47120141983032  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.6027250289917  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.6027250289917  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.67990493774414  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.202260971069336  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.25639295578003  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.20163106918335  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.14822483062744  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.20235729217529  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.3119544982910156  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.11411809921265  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.91947317123413  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.107826232910156  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.107826232910156  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.11452007293701  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 58.00852298736572  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 58.045194149017334  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 58.00809621810913  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.95396423339844  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.99063587188721  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.4180960655212402  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.30796241760254  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.25642204284668  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.30055236816406  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.30055236816406  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.48612689971924  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.343985080718994  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.463860511779785  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.342496395111084  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.30582523345947  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.42570114135742  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

number of input  16976354
----------------------------------------after optimizer
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.5632867813110352  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.643798589706421
pure train time :  3.132944107055664
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  3.2803444862365723
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0022432804107666016
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02659463882446289
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  3.2827746868133545
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.120405435562134
self.buckets_partition() spend  sec:  3.30940842628479
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2908821105957031  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.94682836532593  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.94671392440796  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.939016342163086  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.939016342163086  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.188873291015625  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.21059322357178  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.392985343933105  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.20847225189209  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.0885968208313  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.23577928543091  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.3058247566223145  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.5931396484375  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.472702980041504  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.585585594177246  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.585585594177246  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.68503999710083  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.75647020339966  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.814255714416504  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.75523376464844  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.573405742645264  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.63175582885742  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2123847007751465  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.969666957855225  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.83444166183472  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.962910652160645  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.962910652160645  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.04387903213501  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.05583667755127  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.106085777282715  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.05525207519531  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.99690246582031  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.047152042388916  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2508888244628906  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.422298431396484  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.300564765930176  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.41543674468994  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.41543674468994  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 40.513269901275635  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.363966941833496  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.42144250869751  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.363298416137695  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.31304931640625  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 61.37052536010742  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.2861156463623047  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.829030990600586  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.69316005706787  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.822279930114746  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.822279930114746  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.90244150161743  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.57180452346802  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.625210762023926  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.57118320465088  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.513707637786865  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.56711435317993  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.317739486694336  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.661508083343506  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.524775981903076  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.65476369857788  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.65476369857788  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.733848571777344  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.247780323028564  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.30191230773926  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.24715042114258  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.19374418258667  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 60.24787664413452  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.3075494766235352  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.04932975769043  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.85383224487305  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.042728424072266  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.042728424072266  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.04835653305054  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.943058013916016  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.97972917556763  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.942631244659424  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.88849925994873  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.9251708984375  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.4156756401062012  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.295013427734375  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.24323844909668  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.28760528564453  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.28760528564453  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 39.47288656234741  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.33278846740723  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.45362854003906  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.331299781799316  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.294628620147705  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 59.4154691696167  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

number of input  16973195
----------------------------------------after optimizer
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.5628008842468262  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.5337297916412354
pure train time :  3.1452202796936035
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  3.3102762699127197
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0023102760314941406
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.026760101318359375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  3.312793254852295
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.149165153503418
self.buckets_partition() spend  sec:  3.33959698677063
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.295881748199463  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.99281072616577  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 37.9938530921936  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.984989643096924  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 36.984989643096924  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 38.23629283905029  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.25610065460205  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.43849277496338  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.25378894805908  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.132948875427246  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 57.280004024505615  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.64544677734375 GB
    Memory Allocated: 1.3140034675598145  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 44.72357177734375 GB
    Memory Allocated: 39.83454608917236  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 45.60638427734375 GB
    Memory Allocated: 40.71735858917236  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 45.60638427734375 GB
    Memory Allocated: 39.827895164489746  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 45.60638427734375 GB
    Memory Allocated: 39.827651023864746  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 45.60638427734375 GB
    Memory Allocated: 40.931105613708496  GigaBytes
Max Memory Allocated: 63.839720726013184  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 66.14349365234375 GB
    Memory Allocated: 62.014052867889404  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 66.14349365234375 GB
    Memory Allocated: 62.07183837890625  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 66.14349365234375 GB
    Memory Allocated: 62.01338052749634  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 66.14349365234375 GB
    Memory Allocated: 61.83098840713501  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 66.14349365234375 GB
    Memory Allocated: 61.888774394989014  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 67.52630615234375 GB
    Memory Allocated: 1.2121281623840332  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 67.52630615234375 GB
    Memory Allocated: 39.0479416847229  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 67.52630615234375 GB
    Memory Allocated: 39.91425085067749  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 67.52630615234375 GB
    Memory Allocated: 39.04137134552002  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 67.52630615234375 GB
    Memory Allocated: 39.04117488861084  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 67.52630615234375 GB
    Memory Allocated: 40.12401247024536  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 68.22357177734375 GB
    Memory Allocated: 61.13464593887329  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 68.22357177734375 GB
    Memory Allocated: 61.184895038604736  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 68.22357177734375 GB
    Memory Allocated: 61.134061336517334  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 68.22357177734375 GB
    Memory Allocated: 61.07627582550049  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 68.22357177734375 GB
    Memory Allocated: 61.12652540206909  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.60443115234375 GB
    Memory Allocated: 1.250077724456787  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 39.386348724365234  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 40.26333236694336  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 39.379497051239014  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 39.379497051239014  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 40.47572660446167  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 61.32538604736328  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 61.382861614227295  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 61.32411813735962  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 61.274468421936035  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 61.33256483078003  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 1.279200553894043  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 38.69770431518555  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 39.5592737197876  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 38.69097328186035  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 38.69097328186035  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 39.767935276031494  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 60.453861713409424  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 60.50726795196533  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 60.453240394592285  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 60.39516544342041  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 60.44857215881348  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 1.3139867782592773  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 38.632298946380615  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 39.494243144989014  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 38.62556457519531  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 38.62556457519531  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 69.60638427734375 GB
    Memory Allocated: 39.70299482345581  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 60.21671485900879  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 60.27084684371948  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 60.2160849571228  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 60.162678718566895  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 60.216811180114746  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 1.3095922470092773  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 37.017573833465576  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 37.82238054275513  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 37.01097249984741  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 37.01097249984741  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 38.01698112487793  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 57.91564321517944  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 57.952314376831055  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 57.91521644592285  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 57.86108446121216  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 57.89775609970093  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.30364990234375 GB
    Memory Allocated: 1.4162359237670898  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.30560302734375 GB
    Memory Allocated: 38.29194688796997  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.30560302734375 GB
    Memory Allocated: 39.239988803863525  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.30560302734375 GB
    Memory Allocated: 38.2845401763916  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.30560302734375 GB
    Memory Allocated: 38.2845401763916  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.30560302734375 GB
    Memory Allocated: 39.469592571258545  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.24700927734375 GB
    Memory Allocated: 59.34143543243408  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.24700927734375 GB
    Memory Allocated: 59.46131086349487  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.24700927734375 GB
    Memory Allocated: 59.33994150161743  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.24700927734375 GB
    Memory Allocated: 59.30327033996582  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.24700927734375 GB
    Memory Allocated: 59.42314624786377  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16980316
----------------------------------------after optimizer
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 1.5614304542541504  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.510801315307617
pure train time :  4.742053508758545
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  3.266843795776367
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.002038240432739258
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.028159618377685547
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  3.269240140914917
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.097331762313843
self.buckets_partition() spend  sec:  3.2974393367767334
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 1.2907476425170898  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 36.93608570098877  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 37.93623733520508  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 36.928271770477295  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 36.928271770477295  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 38.17846155166626  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 57.20034980773926  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 57.382741928100586  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 57.198054790496826  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 57.078179359436035  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 79.52630615234375 GB
    Memory Allocated: 57.22595453262329  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 51.72747802734375 GB
    Memory Allocated: 1.3072118759155273  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 51.73724365234375 GB
    Memory Allocated: 39.62700700759888  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 51.73724365234375 GB
    Memory Allocated: 40.50692701339722  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 51.73724365234375 GB
    Memory Allocated: 39.62013244628906  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 51.73724365234375 GB
    Memory Allocated: 39.62013244628906  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 51.73724365234375 GB
    Memory Allocated: 40.720032691955566  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 66.41888427734375 GB
    Memory Allocated: 61.7823224067688  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 66.41888427734375 GB
    Memory Allocated: 61.840107917785645  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 66.41888427734375 GB
    Memory Allocated: 61.78165006637573  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 66.41888427734375 GB
    Memory Allocated: 61.599257946014404  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 66.41888427734375 GB
    Memory Allocated: 61.65704393386841  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 67.80169677734375 GB
    Memory Allocated: 1.2130036354064941  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 67.80169677734375 GB
    Memory Allocated: 39.03000068664551  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 67.80169677734375 GB
    Memory Allocated: 39.89530372619629  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 67.80169677734375 GB
    Memory Allocated: 39.023240089416504  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 67.80169677734375 GB
    Memory Allocated: 39.023240089416504  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 67.80169677734375 GB
    Memory Allocated: 40.10486888885498  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.19818115234375 GB
    Memory Allocated: 61.10954713821411  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.19818115234375 GB
    Memory Allocated: 61.15979623794556  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.19818115234375 GB
    Memory Allocated: 61.108962535858154  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.19818115234375 GB
    Memory Allocated: 61.05117702484131  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.19818115234375 GB
    Memory Allocated: 61.10142660140991  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.19818115234375 GB
    Memory Allocated: 1.2506203651428223  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 39.38424253463745  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 40.26240682601929  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 39.377381801605225  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 39.377381801605225  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 40.47508716583252  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 61.32470178604126  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 61.38217735290527  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 61.32403326034546  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 61.273784160614014  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 61.331260204315186  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 1.2867255210876465  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 38.80950689315796  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 39.67375612258911  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 38.8027548789978  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 38.8027548789978  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 39.88306665420532  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 60.550532817840576  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 60.603939056396484  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 60.54991149902344  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 60.492435932159424  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 60.54584264755249  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 1.3165512084960938  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 38.621689319610596  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 39.48303461074829  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 38.614959716796875  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 38.614959716796875  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 39.691641330718994  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 60.216392040252686  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 60.27052402496338  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 60.2157621383667  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 60.16235589981079  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 60.21648836135864  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 1.3128776550292969  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 37.12925052642822  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 37.935933113098145  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 37.12264919281006  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 37.12264919281006  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 38.13100242614746  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 58.013033390045166  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 58.04970455169678  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 58.012606620788574  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 57.95847463607788  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 57.99514627456665  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.20013427734375 GB
    Memory Allocated: 1.4167990684509277  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.20208740234375 GB
    Memory Allocated: 38.30896282196045  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.20208740234375 GB
    Memory Allocated: 39.25741386413574  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.20208740234375 GB
    Memory Allocated: 38.30155277252197  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.20208740234375 GB
    Memory Allocated: 38.30155277252197  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.20208740234375 GB
    Memory Allocated: 39.48711681365967  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31146240234375 GB
    Memory Allocated: 59.35722494125366  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31146240234375 GB
    Memory Allocated: 59.47710037231445  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31146240234375 GB
    Memory Allocated: 59.35578012466431  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31146240234375 GB
    Memory Allocated: 59.319108963012695  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31146240234375 GB
    Memory Allocated: 59.438984870910645  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16973308
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.5628905296325684  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.312641143798828
pure train time :  3.3891701698303223
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  3.3032469749450684
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0034923553466796875
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.029414653778076172
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  3.3079075813293457
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.1569061279296875
self.buckets_partition() spend  sec:  3.33735728263855
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2901873588562012  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.89779615402222  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.89704179763794  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.889989376068115  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.889989376068115  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.13904666900635  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.15862035751343  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.341012477874756  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.156386852264404  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.03651142120361  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.18280363082886  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3104596138000488  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.616469383239746  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.49760055541992  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.60958528518677  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.60958528518677  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.710999488830566  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.778647899627686  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.83643341064453  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.77797555923462  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.59558343887329  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.653369426727295  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2161083221435547  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.03579521179199  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.902225494384766  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.02902603149414  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.02902603149414  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.11206388473511  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.12193298339844  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.17218208312988  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.12134838104248  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.063562870025635  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.11381244659424  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2486395835876465  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.35308218002319  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.229358196258545  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.34623622894287  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.34623622894287  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.44158124923706  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.294682025909424  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.35215759277344  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.29401350021362  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.24376440048218  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.30124044418335  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.283374309539795  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.75113582611084  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.61351490020752  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.74439811706543  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.74439811706543  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.82237195968628  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.506160736083984  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.55956697463989  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.505539417266846  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.44806385040283  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.5014705657959  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3222708702087402  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.751206398010254  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.61502265930176  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.744457721710205  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.744457721710205  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.824228286743164  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.34287214279175  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.39700412750244  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.34224224090576  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.28883600234985  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.342968463897705  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3101458549499512  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.005009174346924  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.80920648574829  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.99872636795044  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.99872636795044  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.00397300720215  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.88287925720215  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.91955041885376  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.881768226623535  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.82763624191284  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.86499214172363  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.4222369194030762  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.38170051574707  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.331034660339355  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.37428379058838  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.37428379058838  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.560951709747314  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.418203353881836  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.53807878494263  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.41675090789795  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.38007974624634  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.49995565414429  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16979854
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.5681376457214355  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.237790822982788
pure train time :  3.1265788078308105
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  3.4734792709350586
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0019540786743164062
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.027055978775024414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  3.4757604598999023
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.336823463439941
self.buckets_partition() spend  sec:  3.5028553009033203
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2944178581237793  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.99585008621216  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.99709749221802  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.988027572631836  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.988027572631836  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.23958683013916  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.25769090652466  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.440083026885986  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.255515575408936  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.135640144348145  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.282188415527344  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3073234558105469  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.620471477508545  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.50056219100952  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.613595485687256  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.613595485687256  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.71370887756348  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.78004312515259  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.837828636169434  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.77937078475952  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.59697866439819  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.6547646522522  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2146697044372559  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.065650939941406  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.93221664428711  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.05888080596924  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.05888080596924  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.14208793640137  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.15061330795288  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.200862407684326  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.150028705596924  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.09224319458008  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.14249277114868  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2521896362304688  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.442076206207275  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.32082414627075  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.43521070480347  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.43521070480347  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.53364562988281  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.386898040771484  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.4443736076355  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.386229515075684  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.33598041534424  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.39345645904541  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.277536392211914  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.70318794250488  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.564372062683105  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.69645977020264  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.69645977020264  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.772940158843994  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.44659996032715  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.50000619888306  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.44597864151001  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.388503074645996  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.44190979003906  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.315098762512207  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.64689111709595  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.508634090423584  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.64015865325928  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.64015865325928  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.7173376083374  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.23954772949219  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.29367971420288  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.2389178276062  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.18551158905029  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.239644050598145  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3076047897338867  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.986889362335205  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.790685176849365  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.98028802871704  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.98028802871704  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.98503303527832  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.86490726470947  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.901578426361084  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.86448049545288  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.81034851074219  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.84702014923096  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.4192657470703125  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.367496967315674  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.316505908966064  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.36008262634277  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.36008262634277  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.54634380340576  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.40376424789429  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.52363967895508  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.402310848236084  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.36563968658447  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.48551559448242  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16974316
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.565190315246582  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.178269386291504
pure train time :  3.1352314949035645
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  3.4808361530303955
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0048596858978271484
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02778482437133789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  3.4863884449005127
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.303176641464233
self.buckets_partition() spend  sec:  3.514235019683838
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2914624214172363  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.946937084198  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.947049617767334  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.93912363052368  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.93912363052368  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.18926429748535  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.208560943603516  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.390953063964844  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.20643663406372  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.08656120300293  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.23335933685303  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3082289695739746  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.62638568878174  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.5076208114624  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.61950063705444  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.61950063705444  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.72104454040527  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.788838386535645  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.84662389755249  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.78816604614258  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.60577392578125  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.663559913635254  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2136192321777344  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.08972358703613  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.956990242004395  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.082947731018066  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.082947731018066  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.16703128814697  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.17814064025879  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.228389739990234  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.17755603790283  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.119770526885986  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.17002010345459  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2477588653564453  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.347617626190186  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.22468328475952  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.34076547622681  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.34076547622681  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.43709754943848  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.29068470001221  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.34816026687622  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.290016174316406  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.23976707458496  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.29724311828613  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.281423568725586  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.740882396698  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.603177547454834  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.734145641326904  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.734145641326904  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.81201457977295  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.49538564682007  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.54879188537598  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.49476432800293  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.437288761138916  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.49069547653198  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.321141242980957  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.69196128845215  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.55467510223389  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.68522119522095  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.68522119522095  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.7636137008667  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.28698253631592  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.34111452102661  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.28635263442993  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.23294639587402  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.287078857421875  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3139424324035645  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.10631465911865  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.91122341156006  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.10002613067627  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.10002613067627  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.10616207122803  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.98516654968262  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 58.02183771133423  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.984739780426025  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.93060779571533  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.9672794342041  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.4164533615112305  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.27769422531128  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.22459840774536  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.27029609680176  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.27029609680176  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.45392656326294  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.311856746673584  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.431732177734375  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.310372829437256  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.273701667785645  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.393577575683594  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16978740
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.56231689453125  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.0512304306030273
pure train time :  3.128098964691162
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  3.402484178543091
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.002389192581176758
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.028558969497680664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  3.4050452709198
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.216567039489746
self.buckets_partition() spend  sec:  3.433640241622925
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.292989730834961  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.95534610748291  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.95587921142578  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.947529315948486  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.947529315948486  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.198195934295654  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.217002868652344  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.39939498901367  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.214847564697266  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.094972133636475  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.2414436340332  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.308985710144043  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.67943334579468  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.561068058013916  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.672545433044434  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.672545433044434  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.77458906173706  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.84011507034302  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.89790058135986  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.83944272994995  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.65705060958862  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.71483659744263  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2109150886535645  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.03812217712402  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.9031400680542  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.03136396408081  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.03136396408081  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.11263656616211  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.12205410003662  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.172303199768066  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.121469497680664  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.06368398666382  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.11393356323242  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2438011169433594  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.2520637512207  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.12774085998535  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.245222091674805  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.245222091674805  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.339818477630615  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.19460868835449  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.252084255218506  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.19394016265869  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.143691062927246  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.20116710662842  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2845220565795898  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.791943073272705  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.65501642227173  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.785200119018555  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.785200119018555  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.864041805267334  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.546871185302734  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.60027742385864  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.546249866485596  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.48877429962158  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.54218101501465  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3130302429199219  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.58587646484375  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.446818351745605  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.57915019989014  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.57915019989014  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.655327796936035  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.183011054992676  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.23714303970337  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.18238115310669  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.12897491455078  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.18310737609863  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3114795684814453  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.10581159591675  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.9119553565979  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.099210262298584  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.099210262298584  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.1068902015686  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.98458385467529  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 58.021255016326904  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.9841570854187  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.93002510070801  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.96669673919678  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.4130568504333496  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.320265769958496  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.268256187438965  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.312859535217285  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.312859535217285  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.49784755706787  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.355552196502686  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.47542762756348  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.354151248931885  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.31748008728027  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.43735599517822  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16973082
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.5587410926818848  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9670069217681885
pure train time :  3.1257011890411377
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  3.434774160385132
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0023403167724609375
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02902984619140625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  3.437298059463501
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.175414562225342
self.buckets_partition() spend  sec:  3.4663665294647217
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.287092685699463  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.811882972717285  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.809051513671875  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.80409240722656  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.80409240722656  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.05055332183838  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.069952964782715  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.25234508514404  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.06779146194458  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 56.94791603088379  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.09532690048218  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.307703971862793  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.59487962722778  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.47541666030884  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.58800029754639  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.58800029754639  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.688671588897705  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.755391120910645  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.81317663192749  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.75471878051758  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.57232666015625  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.630112648010254  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2141714096069336  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.0134482383728  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.87852716445923  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.00668954849243  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.00668954849243  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.08803844451904  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.09792184829712  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.148170948028564  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.09733724594116  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.039551734924316  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.08980131149292  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2496294975280762  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.351189613342285  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.228620529174805  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.34433460235596  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.34433460235596  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.441123485565186  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.29503536224365  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.352510929107666  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.29436683654785  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.244117736816406  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.30159378051758  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2845706939697266  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.790990352630615  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.65401792526245  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.78424787521362  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.78424787521362  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.86303234100342  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.537442684173584  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.59084892272949  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.536821365356445  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.47934579849243  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.5327525138855  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3190364837646484  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.657429218292236  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.51970720291138  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.65069246292114  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.65069246292114  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.72853994369507  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.24708700180054  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.30121898651123  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.24645709991455  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.19305086135864  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.247183322906494  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3123059272766113  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.0553822517395  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.860188007354736  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.049094676971436  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.049094676971436  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.05510187149048  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.93667221069336  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.97334337234497  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.93624544143677  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.882113456726074  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.918785095214844  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.4248266220092773  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.44777250289917  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.39921808242798  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.44033908843994  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.44033908843994  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.62964630126953  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.48758506774902  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.60806846618652  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.48616361618042  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.44949245452881  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.56997632980347  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16975658
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.5701045989990234  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9373033046722412
pure train time :  3.147115707397461
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.7331743240356445
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.003431558609008789
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.04860186576843262
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.7368743419647217
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.447481393814087
self.buckets_partition() spend  sec:  2.785520076751709
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.287686824798584  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.82365560531616  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.82131814956665  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.815861225128174  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.815861225128174  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.06293964385986  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.08084297180176  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.263235092163086  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.0786919593811  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 56.9582085609436  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.10554122924805  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3078107833862305  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.674779415130615  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.55654859542847  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.667890548706055  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.667890548706055  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.77010202407837  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.835739612579346  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.89352512359619  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.83506727218628  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.65267515182495  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.710461139678955  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2106714248657227  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.99567699432373  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.85999774932861  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.98892402648926  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.98892402648926  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.06932497024536  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.07994270324707  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.130191802978516  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.07935810089111  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.02157258987427  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.07182216644287  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2447805404663086  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.30063772201538  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.176945209503174  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.2937912940979  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.2937912940979  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.38917589187622  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.24276542663574  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.300240993499756  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.24209690093994  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.191847801208496  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.24932384490967  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.283337116241455  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.776301860809326  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.63871908187866  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.769564151763916  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.769564151763916  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.847585678100586  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.52027130126953  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.57367753982544  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.51964998245239  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.46217441558838  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.515581130981445  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3225617408752441  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.76109790802002  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.62537384033203  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.754345417022705  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.754345417022705  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.8346905708313  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.35612154006958  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.41025352478027  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.355491638183594  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.302085399627686  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.35621786117554  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3147854804992676  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.11439800262451  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.92026424407959  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.1081018447876  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.1081018447876  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.115434646606445  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.99304533004761  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 58.02971649169922  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.992618560791016  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.93848657608032  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.97515821456909  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.418891429901123  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.336565017700195  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.28569316864014  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.32914972305298  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.32914972305298  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.515560150146484  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.373164653778076  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.49304008483887  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.37168788909912  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.33501672744751  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.45489263534546  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16974973
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.5637669563293457  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.8685113191604614
pure train time :  3.1012275218963623
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.534731388092041
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.003721475601196289
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02884531021118164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.538625717163086
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.378954887390137
self.buckets_partition() spend  sec:  2.567502975463867
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2910571098327637  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.853893756866455  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.85265016555786  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.84609079360962  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.84609079360962  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.09453630447388  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.11327600479126  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.29566812515259  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.11111402511597  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 56.991238594055176  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.13876295089722  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3067121505737305  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.589086055755615  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.46912431716919  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.582210540771484  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.582210540771484  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.68225860595703  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.75095176696777  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.80873727798462  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.75027942657471  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.56788730621338  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.62567329406738  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2104158401489258  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.97566556930542  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.84004354476929  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.96891260147095  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.96891260147095  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.04938507080078  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.050254344940186  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.10050344467163  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.04966974258423  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.99188423156738  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.042133808135986  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2513847351074219  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.44676685333252  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.325961112976074  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.4398980140686  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.4398980140686  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.53889083862305  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.39284896850586  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.45032453536987  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.39218044281006  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.34193134307861  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.399407386779785  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2824912071228027  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.81473112106323  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.67831563949585  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.807984352111816  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.807984352111816  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.88746500015259  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.556474685668945  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.60988092422485  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.55585336685181  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.49837779998779  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.55178451538086  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3142595291137695  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.63131237030029  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.49310874938965  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.624579429626465  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.624579429626465  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.70182514190674  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.22620677947998  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.280338764190674  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.225576877593994  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.172170639038086  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.22630310058594  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3109445571899414  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.04098701477051  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.84532833099365  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.03470277786255  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.03470277786255  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.04012966156006  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.918715476989746  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.95538663864136  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.91774845123291  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.86361646652222  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.90082836151123  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.4216418266296387  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.39131450653076  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.34096622467041  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.38389492034912  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.38389492034912  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.57095956802368  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.42808246612549  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.54795789718628  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.426634311676025  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.389963150024414  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.50983905792236  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16975341
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.566678524017334  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.8180007934570312
pure train time :  3.098783016204834
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.539703845977783
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0018353462219238281
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02911210060119629
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.542140245437622
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.3322107791900635
self.buckets_partition() spend  sec:  2.571284055709839
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2909655570983887  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.88147306442261  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.8806529045105  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.873666763305664  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.873666763305664  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.12264156341553  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.14104127883911  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.32343339920044  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.13883066177368  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.01895523071289  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.166377544403076  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3053860664367676  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.6157112121582  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.49588871002197  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.608834743499756  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.608834743499756  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.70905685424805  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.77544403076172  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.833229541778564  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.77477169036865  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.592379570007324  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.65016555786133  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2105965614318848  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.016178607940674  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.88125467300415  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.0094199180603  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.0094199180603  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.09076499938965  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.099958419799805  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.15020751953125  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.09937381744385  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.041588306427  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.091837882995605  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.249657154083252  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.37754678726196  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.255430698394775  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.37068796157837  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.37068796157837  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.468042850494385  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.321579933166504  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.37905550003052  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.3209114074707  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.27066230773926  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.32813835144043  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.281740665435791  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.77310562133789  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.63566207885742  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.766366481781006  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.766366481781006  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.84456205368042  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.52758598327637  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.580992221832275  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.52696466445923  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.469489097595215  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.52289581298828  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3231263160705566  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.707924365997314  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.57104253768921  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.701180934906006  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.701180934906006  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.78007888793945  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.300203800201416  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.35433578491211  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.29957389831543  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.24616765975952  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.30030012130737  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3117079734802246  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.072603702545166  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.87665605545044  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.066321849823  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.066321849823  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.07138729095459  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.949374198913574  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.986045360565186  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.94811820983887  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.893986225128174  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.93148708343506  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.4188871383666992  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.330687522888184  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.279550552368164  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.3232741355896  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.3232741355896  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.509353160858154  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.367226123809814  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.487101554870605  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.365747928619385  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.32907676696777  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.44895267486572  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16978312
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.5638399124145508  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.764555811882019
pure train time :  3.0799736976623535
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5223186016082764
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0033652782440185547
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.030079126358032227
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.525874376296997
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.356654405593872
self.buckets_partition() spend  sec:  2.5559847354888916
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.290151596069336  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.89096975326538  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.8905291557312  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.88316059112549  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.88316059112549  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.132609844207764  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.15187311172485  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.33426523208618  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.14973163604736  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.02985620498657  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.17729949951172  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.311629295349121  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.743069648742676  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.62557029724121  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.73586320877075  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.73617506027222  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.839301109313965  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.90431833267212  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.962103843688965  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.90364599227905  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.721253871917725  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.77903985977173  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.214590072631836  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.018473625183105  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.883301734924316  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.01171684265137  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.01171684265137  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.09275197982788  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.10203266143799  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.152281761169434  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.10144805908203  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.043662548065186  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.09391212463379  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2526450157165527  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.312893867492676  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.19014549255371  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.30604028701782  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.30604028701782  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.402605056762695  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.256953716278076  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.31442928314209  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.256285190582275  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.20603609085083  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.263512134552  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2917962074279785  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.83989477157593  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.70387125015259  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.833144664764404  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.833144664764404  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.91311550140381  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.58468246459961  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.63808870315552  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.58406114578247  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.52658557891846  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.57999229431152  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.31931734085083  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.61454677581787  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.475765228271484  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.60781812667847  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.60781812667847  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.68434143066406  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.207401752471924  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.26153373718262  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.20677185058594  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.15336561203003  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.20749807357788  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3150053024291992  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.06815719604492  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.87228012084961  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.06155586242676  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.06155586242676  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.06670951843262  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.94605255126953  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.98272371292114  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.94486713409424  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.890735149383545  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.928165435791016  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.4225568771362305  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.36970233917236  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.31898593902588  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.36228561401367  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.36228561401367  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.548890113830566  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.40651893615723  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.52639436721802  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.405057430267334  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.36838626861572  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.48826217651367  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16979630
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.568223476409912  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7335715293884277
pure train time :  3.092256546020508
the output layer 
self.num_batch (get_in_degree_bucketing) 8
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  8
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.539935827255249
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  8
batches output list generation spend  0.0033631324768066406
self.weights_list  [0.23580098726038143, 0.07470640228168317, 0.06496302536740615, 0.07430546754043932, 0.06904444162796072, 0.06998299340859972, 0.047408876396955214, 0.15497784504203602]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.025989770889282227
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.543497085571289
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.2937116622924805
self.buckets_partition() spend  sec:  2.5695154666900635
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.292048454284668  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.93404769897461  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.934309005737305  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.92623281478882  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 36.92623281478882  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.17655944824219  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.195892333984375  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.3782844543457  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.19367170333862  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.07379627227783  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.2212290763855  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3058576583862305  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.610124588012695  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.490379333496094  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.60324716567993  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.60324716567993  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.70356559753418  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.771241664886475  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.82902717590332  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.77056932449341  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.58817720413208  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.645963191986084  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2138447761535645  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.03759765625  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.903297424316406  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.03083419799805  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.03083419799805  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.112958908081055  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.12180709838867  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.17205619812012  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.121222496032715  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.06343698501587  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.11368656158447  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2485895156860352  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.38996601104736  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.267319679260254  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.38311147689819  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.38311147689819  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 40.47980356216431  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.33221101760864  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.389686584472656  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.33154249191284  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.2812933921814  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 61.33876943588257  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.2822918891906738  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.743468284606934  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.605796813964844  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.73673105239868  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.73673105239868  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.81464195251465  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.484668254852295  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.5380744934082  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.484046936035156  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.42657136917114  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.47997808456421  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3178725242614746  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.72296190261841  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.587162494659424  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.71620988845825  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.71620988845825  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.79646062850952  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.31785011291504  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.37198209762573  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.31722021102905  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.263813972473145  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 60.317946434020996  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.3091602325439453  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.05751085281372  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.86212682723999  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.05122470855713  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 37.05122470855713  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.056994915008545  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.93453550338745  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.97120666503906  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.93410873413086  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.879976749420166  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 57.916648387908936  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.417412281036377  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.347270488739014  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.295405864715576  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.33986282348633  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 38.33986282348633  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 39.52503204345703  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.3826379776001  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.50251340866089  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.38121795654297  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.34454679489136  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 59.46442270278931  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

number of input  16972901
----------------------------------------after optimizer
 Nvidia-smi: 76.59075927734375 GB
    Memory Allocated: 1.5623016357421875  GigaBytes
Max Memory Allocated: 64.0073447227478  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6960515975952148
pure train time :  3.0794756412506104
epoch_time_list  [49.70493841171265, 49.31117653846741, 53.12411546707153, 59.87366986274719, 49.69524526596069, 51.29628229141235, 50.735984563827515, 51.22368335723877, 52.4225378036499, 51.1227126121521, 52.28345322608948, 52.11079931259155, 51.485596656799316, 51.023741722106934, 50.01621770858765, 47.98762845993042, 47.653928995132446, 47.5429790019989, 47.60665249824524, 47.52146244049072]

loading_time list   [0.6272897720336914, 0.7283601760864258, 1.0425176620483398, 0.7460174560546875, 0.7178065776824951, 0.822885274887085, 0.8580646514892578, 0.8035016059875488, 0.6966338157653809, 0.706153154373169, 0.6856377124786377, 0.6583089828491211, 0.6611747741699219, 0.6249082088470459, 0.6115574836730957, 0.5861294269561768, 0.605581521987915, 0.5625104904174805, 0.5611882209777832, 0.5889003276824951]

 data loader gen time  39.89005160331726
	---backpack schedule time  [6.269991159439087, 6.210537433624268, 6.663495302200317, 6.846208810806274, 6.564044237136841, 7.356595754623413, 7.049232006072998, 7.234283924102783, 7.262090444564819, 7.210030555725098, 7.2655110359191895, 7.4429426193237305, 7.409912824630737, 7.326196908950806, 7.27944016456604, 6.572774171829224, 6.483271837234497, 6.438008546829224, 6.460678815841675, 6.396782875061035]
	---connection_check_time_list  [4.499484539031982, 6.050657510757446, 8.549276351928711, 15.96864128112793, 6.36957859992981, 6.74919867515564, 6.695992946624756, 6.681716680526733, 6.666795015335083, 6.541861295700073, 8.215741157531738, 7.755500316619873, 7.39047908782959, 7.000692367553711, 6.262076377868652, 4.7478790283203125, 4.631104946136475, 4.582889080047607, 4.616918563842773, 4.595418930053711]
	---block_gen_time_list  [3.901524782180786, 4.087246417999268, 4.402824401855469, 4.337892293930054, 4.197363615036011, 4.3991639614105225, 4.295645236968994, 4.560108423233032, 4.489420413970947, 4.401501178741455, 4.305531024932861, 4.52919602394104, 4.392260551452637, 4.397170066833496, 4.130258321762085, 4.384629487991333, 4.278540372848511, 4.353694200515747, 4.185060024261475, 4.311690092086792]
training time  [10.10187292098999, 7.240496635437012, 7.396721124649048, 7.192484140396118, 7.203843116760254, 7.145015716552734, 7.140470266342163, 7.172871828079224, 8.704462766647339, 7.746918678283691, 7.0511155128479, 7.061199903488159, 7.042814016342163, 7.052121877670288, 7.097186088562012, 7.111614942550659, 7.045858144760132, 7.043830394744873, 7.04463005065918, 7.036400318145752]
---feature block loading time  [4.549160003662109, 3.740520715713501, 3.9411637783050537, 3.759300947189331, 3.7483978271484375, 3.6946473121643066, 3.699019432067871, 3.718902349472046, 3.6603193283081055, 4.050550699234009, 3.618581771850586, 3.6166954040527344, 3.6066040992736816, 3.620302200317383, 3.642594575881958, 3.706568956375122, 3.641179323196411, 3.659149646759033, 3.647589683532715, 3.6517820358276367]


epoch_time avg   50.108056619763374
loading_time avg   0.6719338893890381
 data loader gen time avg 42.197893515229225
	---backpack schedule time avg 6.984487295150757
	---connection_check_time avg  6.218990191817284
	---block_gen_time avg  4.350702062249184
training time  7.231272101402283
---feature block loading time  3.6864302903413773
pure train time per /epoch  [5.541337966918945, 3.1937355995178223, 3.1482372283935547, 3.1265742778778076, 3.1485891342163086, 3.1433703899383545, 3.132944107055664, 3.1452202796936035, 4.742053508758545, 3.3891701698303223, 3.1265788078308105, 3.1352314949035645, 3.128098964691162, 3.1257011890411377, 3.147115707397461, 3.1012275218963623, 3.098783016204834, 3.0799736976623535, 3.092256546020508, 3.0794756412506104]
pure train time average  3.2319037914276123
num_input list  [16977747, 16980220, 16978063, 16975147, 16976497, 16970006, 16976354, 16973195, 16980316, 16973308, 16979854, 16974316, 16978740, 16973082, 16975658, 16974973, 16975341, 16978312, 16979630, 16972901]
num_input  average  16976183.0
