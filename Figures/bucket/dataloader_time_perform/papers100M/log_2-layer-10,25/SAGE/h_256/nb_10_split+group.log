main start at this time 1713746103.8581297
-----------------------------------------before load data 
 Nvidia-smi: 0.80816650390625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

success----------------------------------------
# Nodes: 111059956
# Edges: 1615685872
# Train: 1207179
# Val: 125265
# Test: 109727512
# Classes: 172

----------------------------------------start of run function 
 Nvidia-smi: 0.80816650390625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5299296379089355
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0018048286437988281
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.04041647911071777
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.532015562057495
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.9672629833221436
self.buckets_partition() spend  sec:  2.5724611282348633
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 2.23724365234375 GB
    Memory Allocated: 1.009434700012207  GigaBytes
Max Memory Allocated: 1.009434700012207  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 41.29779052734375 GB
    Memory Allocated: 36.74362516403198  GigaBytes
Max Memory Allocated: 39.497910499572754  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 42.13177490234375 GB
    Memory Allocated: 37.57760953903198  GigaBytes
Max Memory Allocated: 39.497910499572754  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 42.13177490234375 GB
    Memory Allocated: 36.73769950866699  GigaBytes
Max Memory Allocated: 39.497910499572754  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 42.13177490234375 GB
    Memory Allocated: 36.73711395263672  GigaBytes
Max Memory Allocated: 39.497910499572754  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 42.13177490234375 GB
    Memory Allocated: 37.77944803237915  GigaBytes
Max Memory Allocated: 39.497910499572754  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 60.45794677734375 GB
    Memory Allocated: 56.669321060180664  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 60.45794677734375 GB
    Memory Allocated: 56.72984504699707  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 60.45794677734375 GB
    Memory Allocated: 56.668617248535156  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 60.45794677734375 GB
    Memory Allocated: 56.668617248535156  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 60.45794677734375 GB
    Memory Allocated: 56.72914218902588  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 61.69622802734375 GB
    Memory Allocated: 1.1061224937438965  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 43.08685302734375 GB
    Memory Allocated: 36.125049114227295  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 43.88568115234375 GB
    Memory Allocated: 36.923877239227295  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 43.88568115234375 GB
    Memory Allocated: 36.1191520690918  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 43.88568115234375 GB
    Memory Allocated: 36.11881065368652  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 43.88568115234375 GB
    Memory Allocated: 37.117260456085205  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 59.81341552734375 GB
    Memory Allocated: 55.79030227661133  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 59.81341552734375 GB
    Memory Allocated: 55.83506679534912  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 59.81341552734375 GB
    Memory Allocated: 55.78978157043457  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 59.81341552734375 GB
    Memory Allocated: 55.729257583618164  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 59.81341552734375 GB
    Memory Allocated: 55.774022579193115  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 61.03607177734375 GB
    Memory Allocated: 1.1449799537658691  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 63.29193115234375 GB
    Memory Allocated: 36.91859769821167  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 63.29193115234375 GB
    Memory Allocated: 37.75489282608032  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 63.29193115234375 GB
    Memory Allocated: 36.91206407546997  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 63.29193115234375 GB
    Memory Allocated: 36.91206407546997  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 63.29193115234375 GB
    Memory Allocated: 37.957433223724365  GigaBytes
Max Memory Allocated: 58.35374641418457  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 67.43060302734375 GB
    Memory Allocated: 56.84372663497925  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 67.43060302734375 GB
    Memory Allocated: 56.90622663497925  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 67.43060302734375 GB
    Memory Allocated: 56.84300470352173  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 67.43060302734375 GB
    Memory Allocated: 56.798240184783936  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 67.43060302734375 GB
    Memory Allocated: 56.860740661621094  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 1.1666836738586426  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 35.73745822906494  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 36.523404121398926  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 35.73131799697876  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 35.73131799697876  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 36.71375036239624  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 55.3082480430603  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 55.34874153137207  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 55.307776927948  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 55.245276927948  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 55.285770893096924  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 1.1856555938720703  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 36.21027851104736  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 37.009939193725586  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 36.204030990600586  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 36.204030990600586  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 37.20360708236694  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 55.831833839416504  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 55.87776041030884  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 55.831299781799316  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 55.79080629348755  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 55.83673334121704  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 68.66107177734375 GB
    Memory Allocated: 1.2829580307006836  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 68.66497802734375 GB
    Memory Allocated: 33.69491529464722  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 68.66497802734375 GB
    Memory Allocated: 34.63117742538452  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 68.66497802734375 GB
    Memory Allocated: 33.68760061264038  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 68.66497802734375 GB
    Memory Allocated: 33.68760061264038  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 68.66497802734375 GB
    Memory Allocated: 34.85792827606201  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 51.70258188247681  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 51.88480997085571  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 51.70032215118408  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 51.65439558029175  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 51.83662414550781  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 1.3939123153686523  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 35.78384590148926  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 36.583083152770996  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 35.77760171890259  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 35.77760171890259  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 36.77664852142334  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 55.03065586090088  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 55.08234262466431  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 55.030054569244385  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 54.84782648086548  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 54.899513721466064  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 1.3267426490783691  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 35.18667554855347  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 36.03984498977661  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 35.180009841918945  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 35.180009841918945  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 69.22357177734375 GB
    Memory Allocated: 36.246471881866455  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.34075927734375 GB
    Memory Allocated: 53.89550590515137  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.34075927734375 GB
    Memory Allocated: 53.98984384536743  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.34075927734375 GB
    Memory Allocated: 53.89433002471924  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.34075927734375 GB
    Memory Allocated: 53.84264326095581  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.34075927734375 GB
    Memory Allocated: 53.93698167800903  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 1.031506061553955  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 21.13203477859497  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 21.559882640838623  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 21.127943992614746  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 21.127943992614746  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 21.66275405883789  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 30.165491580963135  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 30.181082248687744  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 30.165770053863525  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 30.070979118347168  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 30.08625364303589  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 0.9698543548583984  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 21.073487281799316  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 21.500638961791992  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 21.070149898529053  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 21.070149898529053  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 21.604089736938477  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 30.105528354644775  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 30.12049961090088  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 30.10505962371826  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 30.090216159820557  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 30.10535430908203  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

number of input  18658509
----------------------------------------after optimizer
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 1.007734775543213  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 4.09311580657959
pure train time :  4.569978475570679
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.7719037532806396
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.013239383697509766
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.05537748336791992
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.7855074405670166
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.430347204208374
self.buckets_partition() spend  sec:  2.840927839279175
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 1.067514419555664  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 36.80314016342163  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 37.63732194900513  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 36.79662275314331  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 36.79662275314331  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 37.83935022354126  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 56.691190242767334  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 56.75171422958374  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 56.690486431121826  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 56.67522096633911  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 56.719406604766846  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.47747802734375 GB
    Memory Allocated: 1.1127371788024902  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 36.159841537475586  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 36.95838260650635  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 36.153602600097656  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 36.153602600097656  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 37.15177917480469  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 55.79494857788086  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 55.83971309661865  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 55.7944278717041  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 55.733903884887695  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 55.77866888046265  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.05755615234375 GB
    Memory Allocated: 1.1499691009521484  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 36.796570777893066  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 37.62967109680176  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 36.790061950683594  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 36.790061950683594  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 37.83143758773804  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 56.71488618850708  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 56.777050495147705  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 56.71416425704956  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 56.66939973831177  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 56.73156452178955  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 1.175745964050293  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 35.82769536972046  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 36.61451768875122  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 35.821547985076904  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 35.821547985076904  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 36.805076122283936  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 55.40253210067749  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 55.44302558898926  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 55.402060985565186  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 55.33989667892456  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 55.380390644073486  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 1.1930532455444336  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 36.23081636428833  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 37.03134298324585  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 36.22456216812134  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 36.22456216812134  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 37.225220680236816  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 55.86240577697754  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 55.90833234786987  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 55.86187171936035  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 55.821378231048584  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 55.867305278778076  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.05950927734375 GB
    Memory Allocated: 1.2940731048583984  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.75636148452759  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 34.693274974823  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.74904155731201  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.74904155731201  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 34.92018365859985  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.765281677246094  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.947509765625  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.763004302978516  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.71707773208618  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.899306297302246  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.4005675315856934  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.78384447097778  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.58375024795532  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.77759504318237  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.77759504318237  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.7774772644043  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.03532028198242  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.08700704574585  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.03471899032593  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 54.85249090194702  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 54.90417814254761  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.3305492401123047  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.16608905792236  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.01815223693848  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.15943193435669  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.15943193435669  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.22451114654541  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.874855041503906  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.96919298171997  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.87371063232422  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.82202386856079  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.916362285614014  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.0401558876037598  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.145040035247803  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.572773456573486  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.141698360443115  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.141698360443115  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.6763653755188  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.177764892578125  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.19274139404297  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.177590370178223  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.083252429962158  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.09822940826416  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 0.9763846397399902  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.119436740875244  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.54716730117798  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.116095066070557  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.116095066070557  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.650758266448975  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.152326583862305  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.167297840118408  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.151498317718506  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.13717555999756  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.15215253829956  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

number of input  18658562
----------------------------------------after optimizer
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.0089383125305176  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.7505273818969727
pure train time :  3.1125621795654297
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5556089878082275
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0070514678955078125
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.03513383865356445
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5628340244293213
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.31865668296814
self.buckets_partition() spend  sec:  2.59799861907959
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.0636677742004395  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.699312686920166  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.5309681892395  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.69281530380249  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.69281530380249  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.73238468170166  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.58705472946167  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.647578716278076  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.58635091781616  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.57072591781616  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.61456775665283  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1087307929992676  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.09145641326904  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.88968563079834  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.08451223373413  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.08451223373413  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.08229875564575  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.731865882873535  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.77663040161133  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.73134517669678  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.67082118988037  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.71558618545532  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1480035781860352  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.90721035003662  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.74237537384033  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.90068531036377  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.90068531036377  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.94464159011841  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.826231479644775  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.888731479644775  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.82584524154663  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.78074502944946  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.842909812927246  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1716690063476562  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.80024337768555  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.58766746520996  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.79409122467041  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.79409122467041  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.77837133407593  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.37523555755615  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.41572904586792  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.37476444244385  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.31260013580322  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.35309410095215  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1940970420837402  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.27332353591919  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.07538175582886  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.26705741882324  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.26705741882324  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.269630432128906  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.90682029724121  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.952746868133545  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.90628623962402  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.865792751312256  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.91171979904175  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.2908940315246582  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.716797828674316  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 34.65313529968262  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.70948266983032  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.70948266983032  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 34.87990474700928  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.725767612457275  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.90799570083618  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.72362947463989  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.67770290374756  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.85993146896362  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.4014935493469238  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.88002681732178  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.680742263793945  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.87377119064331  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.87377119064331  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.8746657371521  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.128864765167236  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.180551528930664  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.12826347351074  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 54.946035385131836  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 54.99772262573242  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.3285021781921387  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.186713218688965  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.03923034667969  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.180052757263184  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.180052757263184  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.245699405670166  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.89469385147095  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.98903179168701  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.893478870391846  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.84179210662842  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.93613052368164  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.0361008644104004  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.192599296569824  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.621148109436035  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.189250946044922  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.189250946044922  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.724936962127686  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.226736068725586  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.24171257019043  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.22639226913452  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.13222360610962  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.147849082946777  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 0.974545955657959  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.1482572555542  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.57589054107666  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.14491605758667  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.14491605758667  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.679457664489746  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.180362224578857  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.19533348083496  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.180021286010742  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.16504192352295  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.18001365661621  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

number of input  18658475
----------------------------------------after optimizer
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.0053954124450684  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.5547165870666504
pure train time :  3.107921838760376
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5686850547790527
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.00415349006652832
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.03268575668334961
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5730347633361816
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.322832107543945
self.buckets_partition() spend  sec:  2.6057660579681396
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.0666537284851074  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.804794788360596  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.63797616958618  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.798285484313965  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.798285484313965  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.83976221084595  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.693185329437256  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.75370931625366  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.69248151779175  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.67734384536743  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.72227239608765  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.110940933227539  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.16720771789551  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.9670352935791  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.160263538360596  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.160263538360596  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.16004800796509  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.79769945144653  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.842463970184326  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.797178745269775  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.73665475845337  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.78141975402832  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1526222229003906  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.92031383514404  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.75593566894531  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.913785457611084  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.913785457611084  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.95831298828125  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.841601848602295  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.90376615524292  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.840879917144775  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.79611539840698  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.858280181884766  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.173215389251709  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.81554841995239  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.60188627243042  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.8094048500061  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.8094048500061  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.79232740402222  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.39061737060547  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.431110858917236  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.390146255493164  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.32798194885254  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.368475914001465  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1949729919433594  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.21250057220459  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.01273822784424  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.20624828338623  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.20624828338623  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.20654535293579  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.842416763305664  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.888343334198  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.84188270568848  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.80138921737671  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.8473162651062  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.2908744812011719  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.67551279067993  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 34.61056852340698  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.66820764541626  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.66820764541626  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 34.83702754974365  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.6817569732666  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.86398506164551  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.67945146560669  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.633524894714355  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.81575345993042  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.3997960090637207  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.79352378845215  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.59245586395264  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.78728199005127  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.78728199005127  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.78594732284546  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.0395245552063  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.09121131896973  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.038923263549805  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 54.8566951751709  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 54.908382415771484  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.3300971984863281  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.09568500518799  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.94653606414795  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.08903741836548  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.08903741836548  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.15260124206543  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.803935527801514  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.89827346801758  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.80281209945679  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.75112533569336  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.84546375274658  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.0382161140441895  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.143846035003662  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.571908473968506  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.140501499176025  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.140501499176025  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.67557954788208  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.17747402191162  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.192450523376465  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.17729949951172  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.082961559295654  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.097938537597656  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 0.9792819023132324  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.13678550720215  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.566655158996582  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.133427143096924  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.133427143096924  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.670764446258545  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.17137384414673  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.186345100402832  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.171199321746826  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.156222820281982  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.171199798583984  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

number of input  18660430
----------------------------------------after optimizer
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.0097250938415527  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.3705623149871826
pure train time :  3.1141536235809326
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.6259846687316895
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.003431081771850586
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.035475730895996094
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.6302449703216553
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.296523571014404
self.buckets_partition() spend  sec:  2.6657629013061523
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.059126853942871  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.68218755722046  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.513325214385986  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.67491436004639  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.67491436004639  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.713836669921875  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.570234298706055  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.63075828552246  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.56953048706055  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.55455923080444  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.59942579269409  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1138710975646973  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.157238483428955  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.9563307762146  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.1509952545166  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.1509952545166  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.149860858917236  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.79098081588745  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.835745334625244  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.79046010971069  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.72993612289429  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.77470111846924  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1476202011108398  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.852452754974365  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.686524868011475  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.84593629837036  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.84593629837036  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.88852643966675  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.772191524505615  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.83435583114624  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.771469593048096  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.7267050743103  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.788869857788086  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1745262145996094  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.825353145599365  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.61348104476929  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.81919574737549  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.81919574737549  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.80435562133789  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.40295934677124  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.44345283508301  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.402488231658936  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.34032392501831  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.380817890167236  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1935744285583496  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.22824048995972  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.02921724319458  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.22198247909546  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.22198247909546  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.22320365905762  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.86097192764282  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.906898498535156  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.860437870025635  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.81994438171387  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.86587142944336  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.2954740524291992  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.715049743652344  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 34.65166759490967  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.70773220062256  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 33.70773220062256  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 34.87850475311279  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.72228288650513  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.90451097488403  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.72013854980469  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.67421197891235  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 51.85644054412842  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.4014267921447754  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.8324818611145  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.63257360458374  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.82623100280762  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.82623100280762  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.826345920562744  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.07586336135864  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.12755012512207  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.07526206970215  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 54.89303398132324  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 54.94472122192383  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.3294010162353516  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.122633934020996  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.974178314208984  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.115981101989746  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 35.115981101989746  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.18041181564331  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.824546813964844  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.91888475418091  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.82344388961792  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.77175712585449  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 53.866095542907715  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.0400619506835938  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.183096885681152  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.611660957336426  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.17974853515625  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.17974853515625  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.715453624725342  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.21751356124878  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.232490062713623  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.217204570770264  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.123001098632812  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.138139247894287  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 0.9794549942016602  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.180831909179688  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.60983943939209  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.176966190338135  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.176966190338135  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 21.713225841522217  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.213788509368896  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.228759765625  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.213613986968994  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.198503017425537  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 30.2134747505188  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

number of input  18660270
----------------------------------------after optimizer
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.0108485221862793  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0989813804626465
pure train time :  3.096585512161255
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.521038055419922
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0035254955291748047
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.034482717514038086
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5247557163238525
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.286656141281128
self.buckets_partition() spend  sec:  2.5592703819274902
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.064194679260254  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.791627407073975  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.62464761734009  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.784714698791504  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.784714698791504  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.825990200042725  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.68075895309448  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.74128293991089  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.680055141448975  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.66508388519287  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 56.71009063720703  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.110727310180664  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.103134632110596  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.901758670806885  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.09689521789551  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 36.09689521789551  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 37.09517526626587  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.74494504928589  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.78970956802368  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.74442434310913  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.683900356292725  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 55.728665351867676  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.06341552734375 GB
    Memory Allocated: 1.1526727676391602  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.9358024597168  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.77169990539551  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.92927169799805  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.92927169799805  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.974143505096436  GigaBytes
Max Memory Allocated: 58.522918701171875  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.86013746261597  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.92230176925659  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.85941553115845  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.814651012420654  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.87681579589844  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.1679177284240723  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.6489372253418  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.433302879333496  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.64280891418457  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.64280891418457  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.62326622009277  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.24443292617798  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.284926414489746  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.243961811065674  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.18179750442505  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.222291469573975  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.1976170539855957  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.28294563293457  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.08393096923828  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.27668762207031  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.27668762207031  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.27791929244995  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.91254472732544  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.95847129821777  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.91201066970825  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.871517181396484  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.91744422912598  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.2972469329833984  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 33.73644781112671  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 34.67317724227905  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 33.72912931442261  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 33.72912931442261  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 34.90004110336304  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.746317863464355  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.92854595184326  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.74417448043823  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.6982479095459  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.88047647476196  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.4037079811096191  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.823537826538086  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.62343788146973  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.817288398742676  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.817288398742676  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.81716346740723  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.065574645996094  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.11726140975952  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.0649733543396  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 54.88274526596069  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 54.93443250656128  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.3302679061889648  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.118022441864014  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.96926259994507  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.111371994018555  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.111371994018555  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.17542219161987  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.82367992401123  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.918017864227295  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.82255840301514  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.77087163925171  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.86521005630493  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.0438718795776367  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.168691635131836  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.59753131866455  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.165340900421143  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.165340900421143  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.701390743255615  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.204230308532715  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.21920680999756  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.203407287597656  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.109717845916748  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.12469482421875  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 0.9763083457946777  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.10455894470215  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.532164573669434  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.101218223571777  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.101218223571777  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.635725498199463  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.13684606552124  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.151817321777344  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.136671543121338  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.121046543121338  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.136672019958496  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

number of input  18652218
----------------------------------------after optimizer
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.0064878463745117  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.866438865661621
pure train time :  3.0793111324310303
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.4595558643341064
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.004060506820678711
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.030091047286987305
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.464026689529419
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.258031845092773
self.buckets_partition() spend  sec:  2.494157075881958
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.0674443244934082  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.812021255493164  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.646240234375  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.80510854721069  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.80510854721069  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.84788227081299  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.70319652557373  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.76372051239014  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.70249271392822  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.68752145767212  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.731626987457275  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.1109094619750977  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.10454797744751  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.90290021896362  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.098310470581055  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.098310470581055  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.096251010894775  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.7418851852417  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.78664970397949  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.74136447906494  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.680840492248535  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.725605487823486  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.1503992080688477  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.90549945831299  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.74075222015381  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.89897394180298  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.89897394180298  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.943039894104004  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.826961040496826  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.88912534713745  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.82623910903931  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.781474590301514  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.8436393737793  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.1761822700500488  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.78344488143921  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.570541858673096  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.77729558944702  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.77729558944702  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.76116704940796  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.35863256454468  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.399126052856445  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.35816144943237  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.29599714279175  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.336491107940674  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.1942567825317383  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.271440505981445  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.07222843170166  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.26518392562866  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.26518392562866  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.26616907119751  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.8986554145813  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.94458198547363  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.89812135696411  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.857627868652344  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.903554916381836  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.2904667854309082  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 33.74779510498047  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 34.68406963348389  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 33.74048042297363  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 33.74048042297363  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 34.910823822021484  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.75573778152466  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.937965869903564  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.753528118133545  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.70760154724121  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.889830112457275  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.3958301544189453  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.72180128097534  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.52016878128052  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.71556377410889  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.71556377410889  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.713523387908936  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 54.96761226654053  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.019299030303955  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 54.96701097488403  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 54.78478288650513  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 54.83647012710571  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.3281245231628418  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.11750030517578  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.96878433227539  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.110849380493164  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.110849380493164  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.174954414367676  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.82613229751587  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.920470237731934  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.82499361038208  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.77330684661865  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.867645263671875  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.039900302886963  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.180879592895508  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.609200477600098  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.17753314971924  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.17753314971924  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.712934494018555  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.214335918426514  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.229312419891357  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.21416139602661  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.119823455810547  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.13480043411255  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 0.9733328819274902  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.090454578399658  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.51831579208374  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.087111473083496  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.087111473083496  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.621938228607178  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.12251329421997  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.137484550476074  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.12233877182007  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.107362270355225  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.122339248657227  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

number of input  18652729
----------------------------------------after optimizer
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.0034031867980957  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.650172233581543
pure train time :  3.0835113525390625
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.6029672622680664
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0039653778076171875
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0336308479309082
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.6071081161499023
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.388826131820679
self.buckets_partition() spend  sec:  2.6407721042633057
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.062032699584961  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.758824825286865  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.5921893119812  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.752135276794434  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.752135276794434  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.79384088516235  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.64741897583008  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.707942962646484  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.64671516418457  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.63174390792847  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.676393032073975  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.1111907958984375  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.11921501159668  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.91693305969238  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.11227083206177  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.11227083206177  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.1094183921814  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.75322723388672  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.79799175262451  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.75270652770996  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.692182540893555  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.736947536468506  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.1464729309082031  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.82321548461914  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.657349586486816  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.81669855117798  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.81669855117798  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.85936641693115  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.74463129043579  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.80713129043579  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.74424505233765  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.69914484024048  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.76130962371826  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.1738643646240234  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.76539611816406  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.551836013793945  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.75925159454346  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.75925159454346  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.74230146408081  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.34076929092407  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.38126277923584  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.34029817581177  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.27813386917114  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.31862783432007  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.1964478492736816  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.340625286102295  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.14244890213013  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.33436059951782  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.33436059951782  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.33664035797119  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.96979284286499  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.015719413757324  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.9692587852478  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.928765296936035  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.97469234466553  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.2959284782409668  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 33.76705598831177  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 34.70343065261841  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 33.759740352630615  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 33.759740352630615  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 34.930208683013916  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.77435874938965  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.956586837768555  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.77222394943237  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.72629737854004  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 51.9085259437561  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.403590202331543  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.79293727874756  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.59329414367676  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.78668403625488  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.78668403625488  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.78713035583496  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.04091215133667  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.0925989151001  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 55.040310859680176  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 54.85808277130127  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 54.909770011901855  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.3313112258911133  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.160977840423584  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.01317834854126  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.154319763183594  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 35.154319763183594  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.21957063674927  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.86666250228882  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.96100044250488  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.86554670333862  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.813859939575195  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 53.90819835662842  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.0386219024658203  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.174376487731934  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.603087425231934  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.171027183532715  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.171027183532715  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.706915855407715  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.208495616912842  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.223472118377686  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.208168029785156  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.113983154296875  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.128960132598877  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 0.9745855331420898  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.093014240264893  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.52019739151001  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.08967685699463  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.08967685699463  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 21.623655796051025  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.1248517036438  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.139822959899902  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.124677181243896  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.10954761505127  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 30.12451934814453  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

number of input  18652771
----------------------------------------after optimizer
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.0056324005126953  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.5298023223876953
pure train time :  3.093597173690796
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.6121387481689453
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0040798187255859375
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.027521610260009766
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.616408586502075
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.441885471343994
self.buckets_partition() spend  sec:  2.643977403640747
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.067948341369629  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.83354043960571  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.66735029220581  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.82685089111328  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 36.82685089111328  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 37.86911344528198  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.723769664764404  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.78429365158081  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.7230658531189  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.70809459686279  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 56.75209426879883  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.31732177734375 GB
    Memory Allocated: 1.116994857788086  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 44.18646240234375 GB
    Memory Allocated: 36.316219329833984  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 44.18646240234375 GB
    Memory Allocated: 37.11802864074707  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 44.18646240234375 GB
    Memory Allocated: 36.30995512008667  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 44.18646240234375 GB
    Memory Allocated: 36.30995512008667  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 44.18646240234375 GB
    Memory Allocated: 37.31221675872803  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 59.97552490234375 GB
    Memory Allocated: 55.978676319122314  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 59.97552490234375 GB
    Memory Allocated: 56.02344083786011  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 59.97552490234375 GB
    Memory Allocated: 55.97815561294556  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 59.97552490234375 GB
    Memory Allocated: 55.91763162612915  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 59.97552490234375 GB
    Memory Allocated: 55.9623966217041  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 61.19818115234375 GB
    Memory Allocated: 1.1518058776855469  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 61.20208740234375 GB
    Memory Allocated: 36.88998889923096  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 61.20208740234375 GB
    Memory Allocated: 37.725335121154785  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 61.20208740234375 GB
    Memory Allocated: 36.88346242904663  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 61.20208740234375 GB
    Memory Allocated: 36.88346242904663  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 61.20208740234375 GB
    Memory Allocated: 37.92834234237671  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 68.98333740234375 GB
    Memory Allocated: 56.82995891571045  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 68.98333740234375 GB
    Memory Allocated: 56.89245891571045  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 68.98333740234375 GB
    Memory Allocated: 56.82923698425293  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 68.98333740234375 GB
    Memory Allocated: 56.78447246551514  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 68.98333740234375 GB
    Memory Allocated: 56.846972942352295  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 1.1737627983093262  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 35.82003211975098  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 36.60735034942627  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 35.813880920410156  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 35.813880920410156  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 36.79802894592285  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 55.395400047302246  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 55.436415672302246  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 55.395225524902344  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 55.33242893218994  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 55.3731484413147  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 1.1938323974609375  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 36.27538347244263  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 37.07606363296509  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 36.26912784576416  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 36.26912784576416  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 37.269978046417236  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 55.91646957397461  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 55.96239614486694  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 55.91593551635742  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 55.875216484069824  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 55.921143531799316  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 70.21380615234375 GB
    Memory Allocated: 1.286886215209961  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 70.21771240234375 GB
    Memory Allocated: 33.629515171051025  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 70.21771240234375 GB
    Memory Allocated: 34.5641188621521  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 70.21771240234375 GB
    Memory Allocated: 33.621904373168945  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 70.21771240234375 GB
    Memory Allocated: 33.621904373168945  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 70.21771240234375 GB
    Memory Allocated: 34.79015922546387  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 51.63487768173218  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 51.817105770111084  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 51.63270139694214  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 51.586774826049805  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 51.76900339126587  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 1.3992419242858887  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 35.83113956451416  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 36.63151741027832  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 35.82407093048096  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 35.82407093048096  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 36.824543476104736  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 55.051047801971436  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 55.10273456573486  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 55.05044651031494  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 54.868218421936035  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 54.91990566253662  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 1.3237390518188477  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 35.06800079345703  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 35.91842174530029  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 35.06071949005127  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 35.06071949005127  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 36.123745918273926  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 53.75554609298706  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 53.849884033203125  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 53.75443363189697  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 53.702746868133545  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 71.04779052734375 GB
    Memory Allocated: 53.79708528518677  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.035595417022705  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.145591259002686  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.574053287506104  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.141940116882324  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.141940116882324  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.677517890930176  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.17939519882202  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.19502019882202  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.17927598953247  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.084882736206055  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.100508213043213  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 0.974940299987793  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.113362312316895  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.541550636291504  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.109711170196533  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.109711170196533  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.644946575164795  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.147366523742676  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.162991523742676  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.147192001342773  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.131622314453125  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.147247791290283  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

number of input  18662263
----------------------------------------after optimizer
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0063214302062988  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.4938063621520996
pure train time :  3.5415492057800293
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.4659500122070312
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.004063129425048828
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02892613410949707
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.4704723358154297
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.201200485229492
self.buckets_partition() spend  sec:  2.499429225921631
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0653319358825684  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.75209283828735  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.58499097824097  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.745585441589355  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.745585441589355  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.78670835494995  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.64175081253052  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.702274799346924  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.64104700088501  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.62542200088501  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.66811513900757  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1107940673828125  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.12901830673218  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.927775859832764  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.122074127197266  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.122074127197266  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.120521068573  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.7825813293457  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.827345848083496  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.782060623168945  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.72153663635254  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.76630163192749  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1505427360534668  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.90194082260132  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.73706007003784  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.895028591156006  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.895028591156006  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.93892765045166  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.822908878326416  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.88507318496704  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.8221869468689  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.7774224281311  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.83958721160889  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1715736389160156  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.80312776565552  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.58935022354126  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.79617977142334  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.79617977142334  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.77895784378052  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.37573719024658  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.41675281524658  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.37556266784668  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.31310176849365  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.35382127761841  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.192537784576416  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.267422676086426  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.06880760192871  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.2604775428772  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.2604775428772  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.26220893859863  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.91134595870972  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.95727252960205  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.91081190109253  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.87009286880493  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.916019916534424  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.2923026084899902  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.74739933013916  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 34.68417453765869  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.73978853225708  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.73978853225708  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 34.910757541656494  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.75479745864868  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.93702554702759  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.7526593208313  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.706732749938965  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.88896131515503  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.3960065841674805  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.739166259765625  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.537991523742676  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.73292541503906  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.73292541503906  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.731457233428955  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.96106433868408  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.01275110244751  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.96046304702759  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.77823495864868  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.82992219924927  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.321913719177246  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.16230583190918  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.01453495025635  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.15564775466919  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.15564775466919  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.22093439102173  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.849806785583496  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.94414472579956  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.84862804412842  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.79694128036499  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.89127969741821  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0355658531188965  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.230509281158447  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.660030841827393  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.227153301239014  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.227153301239014  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.764055252075195  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.266404628753662  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.282029628753662  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.26623010635376  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.171892166137695  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.187517642974854  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 0.9651470184326172  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.05065107345581  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.477582454681396  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.04731559753418  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.04731559753418  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.580979824066162  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.082881450653076  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.098506450653076  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.082706928253174  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.067081928253174  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.082707405090332  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

number of input  18652688
----------------------------------------after optimizer
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 0.9955248832702637  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.2974157333374023
pure train time :  3.081472396850586
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.6758689880371094
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.003811359405517578
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02711796760559082
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.6798830032348633
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.5504724979400635
self.buckets_partition() spend  sec:  2.7070512771606445
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0658378601074219  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.75967216491699  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.59268379211426  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.75316381454468  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.75316381454468  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.79442834854126  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.65356731414795  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.714091300964355  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.65286350250244  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.63723850250244  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.680853843688965  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1091976165771484  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.052109241485596  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.84997320175171  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.045165061950684  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.045165061950684  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.042495250701904  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.70537710189819  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.7504563331604  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.70467233657837  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.64383363723755  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.688913345336914  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1524224281311035  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.941744804382324  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.77826499938965  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.93483257293701  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.93483257293701  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.980483055114746  GigaBytes
Max Memory Allocated: 58.54025650024414  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.865825176239014  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.92798948287964  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.865103244781494  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.8203387260437  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.882503509521484  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1721091270446777  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.81100416183472  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.59810781478882  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.80405616760254  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.80405616760254  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.787935733795166  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.38627624511719  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.42771625518799  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.386229515075684  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.32364082336426  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.36508131027222  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1936979293823242  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.25162982940674  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.0522575378418  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.24468469619751  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.24468469619751  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.24546957015991  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.896074295043945  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.94200086593628  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.89554023742676  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.85452461242676  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.90045166015625  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.2893872261047363  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.7032151222229  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 34.63869905471802  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.69560432434082  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.69560432434082  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 34.86495923995972  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.70959711074829  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.8918251991272  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.70745897293091  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.661532402038574  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.84376096725464  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.4011750221252441  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.875476360321045  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.67610788345337  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.869221210479736  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.869221210479736  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.87001085281372  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.096519470214844  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.14820623397827  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.09591817855835  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.91369009017944  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.96537733078003  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.321906566619873  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.09637784957886  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.94735383987427  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.089096546173096  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.089096546173096  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.15281677246094  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.784443855285645  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.87878179550171  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.78293323516846  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.73124647140503  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.82558488845825  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0323076248168945  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.176714420318604  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.604703426361084  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.173370361328125  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.173370361328125  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.708356857299805  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.21013593673706  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.22576093673706  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.209961414337158  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.115623474121094  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.131248950958252  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 0.9758920669555664  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.1693754196167  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.598342895507812  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.16602373123169  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.16602373123169  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.70223331451416  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.203678607940674  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.219303607940674  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.20350408554077  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.18787908554077  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.20350456237793  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

number of input  18661483
----------------------------------------after optimizer
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.005913257598877  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.226327896118164
pure train time :  3.0801000595092773
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.4044315814971924
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0030536651611328125
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.025182008743286133
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.4076709747314453
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.1241068840026855
self.buckets_partition() spend  sec:  2.4328806400299072
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0669727325439453  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.815279960632324  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.64932155609131  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.80876398086548  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.80876398086548  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.85131597518921  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.71253299713135  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.773056983947754  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.71182918548584  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.69620418548584  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.74023389816284  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1105995178222656  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.13359212875366  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.93245553970337  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.12664794921875  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.12664794921875  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.12522745132446  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.78700256347656  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.831767082214355  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.786481857299805  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.72627258300781  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.771037578582764  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1540613174438477  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.949726581573486  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.7859091758728  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.942814350128174  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.942814350128174  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.9880428314209  GigaBytes
Max Memory Allocated: 58.54594421386719  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.87317991256714  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.935344219207764  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.87245798110962  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.82737874984741  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.889543533325195  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1738262176513672  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.77162456512451  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.55837917327881  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.764676570892334  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.764676570892334  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.748119831085205  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.352808475494385  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.39330196380615  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.35181522369385  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.290173053741455  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.33152484893799  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1979866027832031  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.37036323547363  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.173190116882324  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.363418102264404  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.363418102264404  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.36695194244385  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.012763023376465  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.0586895942688  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.01222896575928  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.97121334075928  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.01714038848877  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.287698745727539  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.687862396240234  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 34.62340068817139  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.680251598358154  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.680251598358154  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 34.849674701690674  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.69392395019531  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.87615203857422  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.69178247451782  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.64585590362549  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.82808446884155  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.3991966247558594  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.804505825042725  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.60370492935181  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.798261642456055  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.798261642456055  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.797260761260986  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.024752616882324  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.07643938064575  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.02415132522583  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.841923236846924  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.89361047744751  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.3219003677368164  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.08922863006592  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.94001388549805  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.082581520080566  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.082581520080566  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.14606332778931  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.77854681015015  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.87288475036621  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.7774338722229  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.72574710845947  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.820085525512695  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0314702987670898  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.12641143798828  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.553624153137207  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.122997283935547  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.122997283935547  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.657013416290283  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.159648895263672  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.175273895263672  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.15947437286377  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.065136432647705  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.080761909484863  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 0.9783129692077637  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.133667469024658  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.562620639801025  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.130253314971924  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.130253314971924  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.666444778442383  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.16776990890503  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.18339490890503  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.167751789093018  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.151970386505127  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.167595863342285  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

number of input  18658681
----------------------------------------after optimizer
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0084095001220703  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.152254819869995
pure train time :  3.0805745124816895
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5441274642944336
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.004443645477294922
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.025585174560546875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.548743724822998
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.3758063316345215
self.buckets_partition() spend  sec:  2.5743582248687744
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0640406608581543  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.77396488189697  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.6068754196167  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.767457485198975  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.767457485198975  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.80859565734863  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.6682505607605  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.728774547576904  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.66754674911499  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.65207815170288  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.69585990905762  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1144661903381348  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.14697504043579  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.94705247879028  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.14003086090088  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.14003086090088  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.140127658843994  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.80365514755249  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.84841966629028  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.80313444137573  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.742610454559326  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.78737545013428  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1495757102966309  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.907883644104004  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.74363708496094  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.90097141265869  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.90097141265869  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.94566345214844  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.8295841217041  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.89174842834473  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.82886219024658  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.78409767150879  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.84626245498657  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.173447608947754  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.830952644348145  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.61852741241455  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.82400465011597  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.82400465011597  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.808473110198975  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.404762268066406  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.445255756378174  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.40376901626587  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.34212684631348  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.383142948150635  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1915082931518555  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.230557918548584  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.03093671798706  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.223612785339355  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.223612785339355  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.22408628463745  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.8639235496521  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.909850120544434  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.86338949203491  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.82237386703491  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.868300914764404  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.2892680168151855  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.69704341888428  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 34.632951736450195  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.6894326210022  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.6894326210022  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 34.859318256378174  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.704078674316406  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.88630676269531  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.70195960998535  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.65603303909302  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.83826160430908  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.3963274955749512  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.73606634140015  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.53396272659302  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.72983264923096  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.72983264923096  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.727203369140625  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.956928730010986  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.008615493774414  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.95632743835449  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.774099349975586  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.82578659057617  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.3314604759216309  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.26197338104248  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.11569118499756  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.255303382873535  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.255303382873535  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.32245063781738  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.95253086090088  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.04686880111694  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.95137596130371  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.89968919754028  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.994027614593506  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0357184410095215  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.19642686843872  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.624356746673584  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.1930832862854  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.1930832862854  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.72799587249756  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.23076105117798  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.24638605117798  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.230586528778076  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.13624858856201  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.15187406539917  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 0.9716110229492188  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.085482120513916  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.512138843536377  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.082148551940918  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.082148551940918  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.615469455718994  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.11734390258789  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.13296890258789  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.11716938018799  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.10154438018799  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.117169857025146  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

number of input  18656526
----------------------------------------after optimizer
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0021905899047852  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.0247912406921387
pure train time :  3.0702292919158936
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.549084186553955
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0037093162536621094
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.029932737350463867
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.55297589302063
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.227064371109009
self.buckets_partition() spend  sec:  2.5829474925994873
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0674586296081543  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.81199073791504  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.64615726470947  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.80547380447388  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.80547380447388  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.8481822013855  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.715128898620605  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.77565288543701  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.7144250869751  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.6988000869751  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.742228984832764  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1162924766540527  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.20689678192139  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.0070161819458  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.199952602386475  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.199952602386475  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.20010185241699  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.861966609954834  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.90673112869263  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.861445903778076  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.801236629486084  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.846001625061035  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1498613357543945  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.885255336761475  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.720130443573  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.87834310531616  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.87834310531616  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.921936988830566  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.80663442611694  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.86879873275757  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.805912494659424  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.76083326339722  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.822998046875  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1729507446289062  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.776939868927  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.56259107589722  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.769991874694824  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.769991874694824  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.75205612182617  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.3541374206543  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.39536714553833  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.353880405426025  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.29150199890137  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.33273220062256  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1914587020874023  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.19427299499512  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.99435615539551  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.18732786178589  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.18732786178589  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.18743181228638  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.82745695114136  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.87338352203369  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.82692289352417  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.78590726852417  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.83183431625366  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.2930240631103516  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.73260450363159  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 34.66885709762573  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.72499370574951  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 33.72499370574951  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 34.89530944824219  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.740699768066406  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.92292785644531  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.73856163024902  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.69263505935669  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 51.874863624572754  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.398819923400879  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.78493309020996  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.58430480957031  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.77786445617676  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.77786445617676  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.7770791053772  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.00355052947998  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.05523729324341  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.002949237823486  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.82072114944458  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 54.872408390045166  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.3212366104125977  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.082900524139404  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.93351411819458  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.07561922073364  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.07561922073364  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.13888645172119  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.76913499832153  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.8634729385376  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.768024921417236  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.71633815765381  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 53.81067657470703  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0355415344238281  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.193519592285156  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.62203884124756  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.190171718597412  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.190171718597412  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.725821018218994  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.228179454803467  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.243804454803467  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.228004932403564  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.1336669921875  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.149292469024658  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 0.970613956451416  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.098371028900146  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.526211261749268  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.095028400421143  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.095028400421143  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 21.629828929901123  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.131747245788574  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.147372245788574  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.131572723388672  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.115947723388672  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 30.13157320022583  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

number of input  18654988
----------------------------------------after optimizer
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0012860298156738  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9632891416549683
pure train time :  3.079249143600464
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.4685473442077637
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0028171539306640625
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.026335716247558594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.4715371131896973
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.088371992111206
self.buckets_partition() spend  sec:  2.498025894165039
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.0619592666625977  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.718607902526855  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.55070114135742  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.712106704711914  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.712106704711914  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.7522234916687  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.611791133880615  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.67231512069702  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.61108732223511  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.59546232223511  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.638150215148926  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.110163688659668  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.08541440963745  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.88298940658569  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.07918310165405  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.07918310165405  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.076151847839355  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.7372407913208  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.78232002258301  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.73653602600098  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.675697326660156  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.72077703475952  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.151017665863037  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.85021924972534  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.684935092926025  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.843698024749756  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.843698024749756  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.88709306716919  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.77133560180664  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.833499908447266  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.77061367034912  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.72584915161133  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 56.78801393508911  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1763434410095215  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.80805444717407  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.59486532211304  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.80190706253052  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 35.80190706253052  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.7854208946228  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.38602352142334  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.42651700973511  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.3850302696228  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.32338809967041  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.36484670639038  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 1.1966052055358887  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.25852108001709  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.05984973907471  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.25226068496704  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 36.25226068496704  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 37.25392150878906  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.89942121505737  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.94534778594971  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.898887157440186  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.857871532440186  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 72.18450927734375 GB
    Memory Allocated: 55.90379858016968  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 1.292097568511963  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 33.70673942565918  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 34.64271068572998  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 33.699427127838135  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 33.699427127838135  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 34.869391441345215  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 51.71387195587158  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 51.89610004425049  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 51.71171283721924  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 51.665786266326904  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 51.84801483154297  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 1.4032392501831055  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 35.84947156906128  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.649845600128174  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 35.84301996231079  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 35.84301996231079  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.84348773956299  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.071410179138184  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.12309694290161  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.07080888748169  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 54.88858079910278  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 54.94026803970337  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 1.3258423805236816  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 35.084068775177  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 35.93553304672241  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 35.07678747177124  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 35.07678747177124  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.14111804962158  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 53.77333974838257  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 53.86767768859863  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 53.77217721939087  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 53.72049045562744  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 53.814828872680664  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 1.0363998413085938  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 21.171767711639404  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 21.59960126876831  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 21.1684250831604  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 21.1684250831604  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 21.703217029571533  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 30.205239295959473  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 30.220864295959473  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 30.20506477355957  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 30.110726833343506  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 30.126352310180664  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 0.9776525497436523  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 21.211002826690674  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 21.64145803451538  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 21.207639694213867  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 21.207639694213867  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 21.74570894241333  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 30.24735927581787  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 30.26298427581787  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 30.24718475341797  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 30.23155975341797  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 30.247185230255127  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

number of input  18659360
----------------------------------------after optimizer
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 1.0078954696655273  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9217764139175415
pure train time :  3.0843870639801025
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.679828643798828
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0038805007934570312
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02532672882080078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.68389892578125
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.392023086547852
self.buckets_partition() spend  sec:  2.709275007247925
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 1.0631318092346191  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.69134712219238  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 37.523037910461426  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.68481922149658  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.68481922149658  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 37.724432945251465  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 56.580424785614014  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 56.64094877243042  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 56.579720973968506  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 56.564095973968506  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 56.608150482177734  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 1.1094284057617188  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.09706115722656  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.895052909851074  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.09011697769165  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.09011697769165  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 37.08760690689087  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.751601219177246  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.79636573791504  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.75108051300049  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.69055652618408  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.73532152175903  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 1.1477718353271484  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.93030595779419  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 37.76544237136841  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.923781394958496  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.923781394958496  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 37.96770191192627  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 56.85153532028198  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 56.91369962692261  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 56.85081338882446  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 56.80604887008667  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 56.86821365356445  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 1.1671738624572754  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 35.71924304962158  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.5046443939209  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 35.713106632232666  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 35.713106632232666  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 36.69485855102539  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.29352569580078  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.33401918411255  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.292532444000244  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.23089027404785  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 55.27138423919678  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.40716552734375 GB
    Memory Allocated: 1.1898102760314941  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.2342209815979  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 37.03504514694214  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.22796440124512  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.22796440124512  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 37.228994846343994  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.87988090515137  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.9258074760437  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.87934684753418  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.83833122253418  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.88425827026367  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 1.2882518768310547  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 33.75072002410889  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 34.687378883361816  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 33.74340200424194  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 33.74340200424194  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 34.914225578308105  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 51.75835943222046  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 51.940587520599365  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 51.756187915802  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 51.71026134490967  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 51.89248991012573  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 1.3993825912475586  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 35.87655162811279  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.67782020568848  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 35.86948299407959  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 35.86948299407959  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.87106895446777  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.09774351119995  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.14943027496338  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.09714221954346  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 54.91491413116455  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 54.96660137176514  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 1.3226594924926758  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 35.15472650527954  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.005783557891846  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 35.14807748794556  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 35.14807748794556  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.21189880371094  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 53.84292030334473  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 53.93725824356079  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 53.841801166534424  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 53.790114402770996  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 53.88445281982422  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 1.0331945419311523  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 21.15160322189331  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 21.580365657806396  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 21.148253440856934  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 21.148253440856934  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 21.68420648574829  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 30.185973167419434  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 30.201598167419434  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 30.18579864501953  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 30.091460704803467  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 30.107086181640625  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 0.9709100723266602  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 21.167792320251465  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 21.59763526916504  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 21.16443395614624  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 21.16443395614624  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 21.701737880706787  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 30.203503131866455  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 30.219128131866455  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 30.203328609466553  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 30.187703609466553  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 30.20332908630371  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

number of input  18658166
----------------------------------------after optimizer
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 1.0012178421020508  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.852878451347351
pure train time :  3.075357675552368
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5644962787628174
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0033113956451416016
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.030183076858520508
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.568197727203369
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.175337791442871
self.buckets_partition() spend  sec:  2.5984113216400146
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 1.0626826286315918  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.68467378616333  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 37.515660762786865  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.67735147476196  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.67735147476196  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 37.71608543395996  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.5758581161499  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.63638210296631  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.575154304504395  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.559529304504395  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.60342597961426  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 1.112471580505371  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.079073905944824  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.877197265625  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.072838306427  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.072838306427  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 37.0704927444458  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.73413610458374  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.77921533584595  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.733431339263916  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.672592639923096  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.71767234802246  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 1.1482601165771484  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.89124250411987  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 37.72631311416626  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.88471841812134  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.88471841812134  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 37.9285569190979  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.81459283828735  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.87675714492798  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.813870906829834  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.76910638809204  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.831271171569824  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 1.1703190803527832  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 35.74932336807251  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.534778118133545  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 35.743186950683594  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 35.743186950683594  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.72500562667847  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.32383394241333  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.3643274307251  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.32284069061279  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.2611985206604  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.301692485809326  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 1.1985788345336914  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.343878746032715  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 37.146817207336426  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.337605476379395  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 36.337605476379395  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 37.34127855300903  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.99095582962036  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 56.036882400512695  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.990421772003174  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.949406147003174  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.98333740234375 GB
    Memory Allocated: 55.995333194732666  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.2948627471923828  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 33.822853565216064  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 34.76082944869995  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 33.8155255317688  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 33.8155255317688  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 34.987995624542236  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 51.832115173339844  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 52.01434326171875  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 51.82994365692139  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 51.78401708602905  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 51.96624565124512  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.3946409225463867  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.75636911392212  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.554561138153076  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.75013303756714  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.75013303756714  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.747873306274414  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 54.974403381347656  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.026090145111084  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 54.97380208969116  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 54.791574001312256  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 54.84326124191284  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.325913906097412  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.154725551605225  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.00661897659302  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.148069858551025  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.148069858551025  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.212936878204346  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 53.839200496673584  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 53.93353843688965  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 53.83808994293213  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 53.7864031791687  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 53.880741596221924  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.0376558303833008  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.171621322631836  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.59988498687744  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.168275356292725  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.168275356292725  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.70360517501831  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.205738067626953  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.221363067626953  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.20556354522705  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.111225605010986  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.126851081848145  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 0.9770817756652832  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.14272928237915  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.571268558502197  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.13937759399414  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.13937759399414  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.67505168914795  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.17671251296997  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.19233751296997  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.17653799057007  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.16091299057007  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.176538467407227  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

number of input  18657347
----------------------------------------after optimizer
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.0070090293884277  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.8044672012329102
pure train time :  3.0899834632873535
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.403093099594116
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.001676321029663086
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02830362319946289
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.4049227237701416
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.187120676040649
self.buckets_partition() spend  sec:  2.4332547187805176
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.064321517944336  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.733309745788574  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 37.56531047821045  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.72680950164795  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.72680950164795  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 37.76681041717529  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.62724828720093  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.687772274017334  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.62654447555542  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.61091947555542  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.65503454208374  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.1092286109924316  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.077924728393555  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.87647724151611  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.071685791015625  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.071685791015625  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 37.0698766708374  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.73196268081665  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.77704191207886  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.73175668716431  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.670917987823486  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.71599769592285  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.150205135345459  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.92324638366699  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 37.75877285003662  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.91671848297119  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.91671848297119  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 37.96112680435181  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.84688186645508  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.9090461730957  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.84615993499756  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.801395416259766  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.86356019973755  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.1704378128051758  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.78831720352173  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.5746693611145  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.78217363357544  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.78217363357544  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.765113830566406  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.368712425231934  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.4092059135437  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.3677191734314  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.306077003479004  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.34749746322632  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.1978869438171387  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.29978704452515  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 37.10173749923706  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.29352140426636  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.29352140426636  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 37.29595947265625  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.943928241729736  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.98985481262207  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.94339418411255  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.90237855911255  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.94830560684204  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.294461727142334  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 33.767032623291016  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 34.703683853149414  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 33.75971460342407  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 33.75971460342407  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 34.93052864074707  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 51.775567054748535  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 51.95779514312744  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 51.77339553833008  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 51.727468967437744  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 51.90969753265381  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.402681827545166  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.827876567840576  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.62730073928833  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.82163095474243  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.82163095474243  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.8209114074707  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.04885244369507  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.100539207458496  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.048251152038574  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 54.86602306365967  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 54.917710304260254  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.3305716514587402  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.123445987701416  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.97515535354614  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.11679172515869  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 35.11679172515869  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.1814284324646  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 53.81085538864136  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 53.90519332885742  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 53.809722900390625  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 53.7580361366272  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 53.85237455368042  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.0363502502441406  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.183337211608887  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.610551834106445  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.179999351501465  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.179999351501465  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.714017868041992  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.21565580368042  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.23128080368042  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.21604585647583  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.121143341064453  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.13676881790161  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 0.9759869575500488  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.097131729125977  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.525582313537598  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.09324312210083  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.09324312210083  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 21.628806591033936  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.13083839416504  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.14646339416504  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.130663871765137  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.11560344696045  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 30.130664348602295  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

number of input  18658534
----------------------------------------after optimizer
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.007370948791504  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7567402124404907
pure train time :  3.09027099609375
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.580510377883911
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.004508256912231445
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.03151059150695801
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.585200548171997
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.459630727767944
self.buckets_partition() spend  sec:  2.6167447566986084
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.0638256072998047  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.73481559753418  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 37.56758117675781  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.7283091545105  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.7283091545105  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 37.76926612854004  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.62864685058594  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.689170837402344  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.62794303894043  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.61231803894043  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 56.655632972717285  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.1129097938537598  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.17353296279907  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.9734206199646  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.16658878326416  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 36.16658878326416  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 37.16644859313965  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.828510761260986  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.87327527999878  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.82799005508423  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.767780780792236  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 55.81254577636719  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 76.20599365234375 GB
    Memory Allocated: 1.152479648590088  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.97788095474243  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 37.813735485076904  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.97096872329712  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.97096872329712  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 38.01578712463379  GigaBytes
Max Memory Allocated: 58.55329895019531  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.90175724029541  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.963921546936035  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.90103530883789  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.855956077575684  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.91812086105347  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.171241283416748  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.731417179107666  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.51703596115112  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.72446918487549  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.72446918487549  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.70649290084839  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.308764934539795  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.34925842285156  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.30777168273926  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.246129512786865  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.287519454956055  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.1959776878356934  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.25930452346802  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 37.06088876724243  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.25235939025879  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.25235939025879  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 37.25433969497681  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.90156555175781  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.94749212265015  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.901031494140625  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.860015869140625  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.90594291687012  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.2950639724731445  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 33.76104927062988  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 34.69813251495361  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 33.75372791290283  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 33.75372791290283  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 34.925082206726074  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 51.769447326660156  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 51.95167541503906  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 51.76730918884277  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 51.72138261795044  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 51.903611183166504  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.3945088386535645  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.74622392654419  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.54448652267456  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.739155292510986  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.739155292510986  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.73698377609253  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 54.96542978286743  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.01711654663086  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 54.96482849121094  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 54.78260040283203  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 54.83428764343262  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.3256988525390625  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.154826641082764  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.00680875778198  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.147545337677  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.147545337677  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.212522983551025  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 53.84168577194214  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 53.9360237121582  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 53.84050464630127  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 53.78881788253784  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 53.883156299591064  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.0321168899536133  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.16455841064453  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.591970443725586  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.161219120025635  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.161219120025635  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.695484161376953  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.19783878326416  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.21346378326416  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.197664260864258  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.103326320648193  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.11895179748535  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 0.972407341003418  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.119868278503418  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.5488224029541  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.116517066955566  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.116517066955566  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.6527099609375  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.154170513153076  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.169795513153076  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.153995990753174  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.138370990753174  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.153996467590332  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

number of input  18662203
----------------------------------------after optimizer
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.0021185874938965  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7259451150894165
pure train time :  3.0971407890319824
the output layer 
self.num_batch (get_in_degree_bucketing) 10
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  10
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[14, 8, 7], [10, 17, 18], [13, 9, 6], [15, 16, 19], [11, 12, 21], [4, 1, 0], [20, 22, 5], [23, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.6183958053588867
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  10
current group_mem  36.0004677772522
current group_mem  35.998389065265656
current group_mem  35.98673942685127
current group_mem  35.95910704135895
current group_mem  35.957984268665314
current group_mem  24.562401205301285
current group_mem  34.028565645217896
current group_mem  29.991439819335938
batches output list generation spend  0.0032088756561279297
self.weights_list  [0.07824688799258436, 0.05787211341482912, 0.08025570358662634, 0.052350976947080755, 0.05937479031692897, 0.23558892260385578, 0.06682190462226398, 0.121962028829196, 0.019361668816306448, 0.01935504179579002]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.032631874084472656
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.621804714202881
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.385217666625977
self.buckets_partition() spend  sec:  2.6544957160949707
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.065737247467041  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.77561283111572  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 37.609185218811035  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.769100189208984  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.769100189208984  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 37.811065673828125  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.67091417312622  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.73143815994263  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.67021036148071  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.65458536148071  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.69902753829956  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.110074520111084  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.11316967010498  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.911383628845215  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.10622549057007  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.10622549057007  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 37.10399293899536  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.76772403717041  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.81280326843262  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.767019271850586  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.706180572509766  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.75126028060913  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.1506352424621582  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.923808574676514  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 37.75950574874878  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.9168963432312  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.9168963432312  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 37.96151781082153  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.846861362457275  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.9090256690979  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.846139430999756  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.80137491226196  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.863539695739746  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.1718387603759766  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.76582336425781  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.55177116394043  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.758875370025635  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.758875370025635  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.741310119628906  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.34953451156616  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.39002799987793  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.348541259765625  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.28689908981323  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.32797050476074  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.1939353942871094  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.329737186431885  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 37.13164186477661  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.322792053222656  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.322792053222656  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 37.325172901153564  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.96981382369995  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 56.015740394592285  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.969279766082764  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.928264141082764  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.974191188812256  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.2886323928833008  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 33.70794486999512  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 34.643733978271484  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 33.70033407211304  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 33.70033407211304  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 34.870070457458496  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 51.7139630317688  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 51.896191120147705  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 51.71182155609131  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 51.665894985198975  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 51.84812355041504  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.3966450691223145  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.82444381713867  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.62448978424072  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.818193435668945  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.818193435668945  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.81825113296509  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.04766130447388  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.099348068237305  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 55.04706001281738  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 54.86483192443848  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 54.91651916503906  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.3232955932617188  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.12901306152344  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.981263160705566  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.12235450744629  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 35.12235450744629  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 36.18766736984253  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 53.81751775741577  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 53.911855697631836  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 53.81629705429077  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 53.764610290527344  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 53.858948707580566  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.0312328338623047  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.143296718597412  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.571123600006104  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.139954090118408  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.139954090118408  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.67473793029785  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.176855087280273  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.192480087280273  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.17668056488037  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.082342624664307  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.097968101501465  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

step  9
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 0.971961498260498  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.14579153060913  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.5737042427063  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.14244842529297  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.14244842529297  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 21.677339553833008  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.17923593521118  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.19486093521118  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.17906141281128  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.16343641281128  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 30.179061889648438  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

number of input  18652580
----------------------------------------after optimizer
 Nvidia-smi: 78.46185302734375 GB
    Memory Allocated: 1.0024285316467285  GigaBytes
Max Memory Allocated: 58.581876277923584  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6810452938079834
pure train time :  3.118968963623047
epoch_time_list  [49.74917507171631, 50.76044964790344, 49.99138593673706, 51.50646162033081, 55.221617460250854, 48.33774495124817, 48.35902547836304, 48.34297251701355, 48.95800304412842, 47.82371377944946, 48.29777145385742, 47.57540273666382, 48.147141218185425, 47.88371515274048, 48.36972689628601, 48.78686594963074, 47.96109104156494, 48.472991704940796, 50.101402282714844, 48.36363697052002]

loading_time list   [0.6298544406890869, 0.7145886421203613, 0.8192377090454102, 0.898775577545166, 0.9634158611297607, 0.645012378692627, 0.6229977607727051, 0.6313562393188477, 0.6147027015686035, 0.606299638748169, 0.6081357002258301, 0.5143210887908936, 0.6030468940734863, 0.5524680614471436, 0.5805559158325195, 0.6574347019195557, 0.5835027694702148, 0.531674861907959, 0.5835428237915039, 0.6305265426635742]

 data loader gen time  40.21450209617615
	---backpack schedule time  [7.080023765563965, 7.576441287994385, 7.430718421936035, 7.455972194671631, 7.4114649295806885, 7.3948845863342285, 7.365648031234741, 7.495655059814453, 7.548706531524658, 7.3092405796051025, 7.662418603897095, 7.22620153427124, 7.482187509536743, 7.323290824890137, 7.194284677505493, 7.499765157699585, 7.279297590255737, 7.289670944213867, 7.568178176879883, 7.4967498779296875]
	---connection_check_time_list  [4.642831087112427, 6.287224292755127, 4.794203996658325, 6.486738920211792, 11.139711141586304, 4.858482599258423, 4.834171772003174, 4.979912519454956, 4.9631006717681885, 4.895543098449707, 4.863518714904785, 4.734235763549805, 4.893497705459595, 5.065488576889038, 5.423943281173706, 5.478291988372803, 5.127821445465088, 5.120808839797974, 7.1018030643463135, 5.019347429275513]
	---block_gen_time_list  [3.4782450199127197, 3.530515432357788, 3.6121132373809814, 3.469003200531006, 3.570390224456787, 3.461458444595337, 3.5175416469573975, 3.5033953189849854, 3.492832899093628, 3.3768374919891357, 3.5193190574645996, 3.5681748390197754, 3.4308359622955322, 3.2814230918884277, 3.419213056564331, 3.419658899307251, 3.1049394607543945, 3.653640031814575, 3.0397677421569824, 3.2748398780822754]
training time  [9.740319967269897, 7.374324321746826, 7.935786962509155, 8.069801807403564, 7.580101490020752, 7.284097194671631, 7.41549825668335, 7.366516351699829, 7.959575414657593, 7.301367282867432, 7.300641059875488, 7.242849826812744, 7.3107147216796875, 7.266803503036499, 7.276977300643921, 7.303788185119629, 7.253311634063721, 7.451671361923218, 7.530308485031128, 7.513920545578003]
---feature block loading time  [5.159920930862427, 4.09018349647522, 4.6561853885650635, 4.781625032424927, 4.310146808624268, 4.03354811668396, 4.156378269195557, 4.099765777587891, 4.2449421882629395, 4.048036575317383, 4.047405004501343, 3.989776849746704, 4.068086624145508, 4.015978574752808, 4.020871877670288, 4.057176351547241, 3.9901914596557617, 4.1902756690979, 4.260689735412598, 4.222002744674683]


epoch_time avg   48.812676414847374
loading_time avg   0.6205621212720871
 data loader gen time avg 40.79025657474995
	---backpack schedule time avg 7.409227788448334
	---connection_check_time avg  5.531229913234711
	---block_gen_time avg  3.4146417528390884
training time  7.397383913397789
---feature block loading time  4.109704539179802
pure train time per /epoch  [4.569978475570679, 3.1125621795654297, 3.107921838760376, 3.1141536235809326, 3.096585512161255, 3.0793111324310303, 3.0835113525390625, 3.093597173690796, 3.5415492057800293, 3.081472396850586, 3.0801000595092773, 3.0805745124816895, 3.0702292919158936, 3.079249143600464, 3.0843870639801025, 3.075357675552368, 3.0899834632873535, 3.09027099609375, 3.0971407890319824, 3.118968963623047]
pure train time average  3.1150848444770363
num_input list  [18658509, 18658562, 18658475, 18660430, 18660270, 18652218, 18652729, 18652771, 18662263, 18652688, 18661483, 18658681, 18656526, 18654988, 18659360, 18658166, 18657347, 18658534, 18662203, 18652580]
num_input  average  18657439.15
