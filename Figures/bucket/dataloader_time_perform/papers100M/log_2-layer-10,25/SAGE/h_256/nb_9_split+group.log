main start at this time 1713744522.5343864
-----------------------------------------before load data 
 Nvidia-smi: 0.80816650390625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

success----------------------------------------
# Nodes: 111059956
# Edges: 1615685872
# Train: 1207179
# Val: 125265
# Test: 109727512
# Classes: 172

----------------------------------------start of run function 
 Nvidia-smi: 0.80816650390625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5327439308166504
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0021719932556152344
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.038815975189208984
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.535172462463379
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.738927125930786
self.buckets_partition() spend  sec:  2.57401442527771
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 2.30950927734375 GB
    Memory Allocated: 1.0780634880065918  GigaBytes
Max Memory Allocated: 1.0780634880065918  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 39.57318115234375 GB
    Memory Allocated: 35.11089038848877  GigaBytes
Max Memory Allocated: 37.37027454376221  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 40.53802490234375 GB
    Memory Allocated: 36.07573413848877  GigaBytes
Max Memory Allocated: 37.37027454376221  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 40.53802490234375 GB
    Memory Allocated: 35.103686809539795  GigaBytes
Max Memory Allocated: 37.37027454376221  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 40.53802490234375 GB
    Memory Allocated: 35.103354930877686  GigaBytes
Max Memory Allocated: 37.37027454376221  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 40.53802490234375 GB
    Memory Allocated: 36.30932664871216  GigaBytes
Max Memory Allocated: 37.37027454376221  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 57.75677490234375 GB
    Memory Allocated: 54.23502969741821  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 57.75677490234375 GB
    Memory Allocated: 54.41534185409546  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 57.75677490234375 GB
    Memory Allocated: 54.23290967941284  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 57.75677490234375 GB
    Memory Allocated: 54.23290967941284  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 57.75677490234375 GB
    Memory Allocated: 54.413222789764404  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 60.01068115234375 GB
    Memory Allocated: 1.2660679817199707  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 46.97161865234375 GB
    Memory Allocated: 38.27818584442139  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 46.97161865234375 GB
    Memory Allocated: 39.128013610839844  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 46.97161865234375 GB
    Memory Allocated: 38.271546363830566  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 46.97161865234375 GB
    Memory Allocated: 38.271546363830566  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 46.97161865234375 GB
    Memory Allocated: 39.33383131027222  GigaBytes
Max Memory Allocated: 55.721105098724365  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 63.48529052734375 GB
    Memory Allocated: 59.293482303619385  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 63.48529052734375 GB
    Memory Allocated: 59.34918785095215  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 63.48529052734375 GB
    Memory Allocated: 59.29283428192139  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 63.48529052734375 GB
    Memory Allocated: 59.11252212524414  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 63.48529052734375 GB
    Memory Allocated: 59.16822814941406  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 64.78997802734375 GB
    Memory Allocated: 1.1690006256103516  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 64.79388427734375 GB
    Memory Allocated: 37.64911508560181  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 64.79388427734375 GB
    Memory Allocated: 38.4847092628479  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 64.79388427734375 GB
    Memory Allocated: 37.64258670806885  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 64.79388427734375 GB
    Memory Allocated: 37.64258670806885  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 64.79388427734375 GB
    Memory Allocated: 38.687079429626465  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 67.80560302734375 GB
    Memory Allocated: 58.524189472198486  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 67.80560302734375 GB
    Memory Allocated: 58.57235860824585  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 67.80560302734375 GB
    Memory Allocated: 58.5236291885376  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 67.80560302734375 GB
    Memory Allocated: 58.467923641204834  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 67.80560302734375 GB
    Memory Allocated: 58.516093254089355  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 1.202517032623291  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 37.88137769699097  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 38.72692632675171  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 37.87477159500122  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 37.87477159500122  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 38.93170738220215  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 58.67676305770874  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 58.73215866088867  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 58.67611885070801  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 58.627949714660645  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 58.683345794677734  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 1.2310304641723633  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 37.26815366744995  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 38.098567485809326  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 37.26166582107544  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 37.26166582107544  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 38.29968309402466  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 57.85375165939331  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 57.90507793426514  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 57.85315465927124  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 57.79775905609131  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 57.84908580780029  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 1.2646822929382324  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 37.16624355316162  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 37.9957971572876  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 37.159762382507324  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 37.159762382507324  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 38.196704387664795  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 57.61253833770752  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 57.66459035873413  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 57.6119327545166  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 57.560606479644775  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 57.61319017410278  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 1.2612695693969727  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 35.722856521606445  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 36.4981803894043  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 35.71679925918579  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 35.71679925918579  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 36.685954093933105  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 55.4740104675293  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 55.508601665496826  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 55.47360801696777  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 55.42155599594116  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 55.45614767074585  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 69.10833740234375 GB
    Memory Allocated: 1.3590936660766602  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 69.11029052734375 GB
    Memory Allocated: 36.70652198791504  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 69.11029052734375 GB
    Memory Allocated: 37.62092304229736  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 69.11029052734375 GB
    Memory Allocated: 36.69937801361084  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 69.11029052734375 GB
    Memory Allocated: 36.69937801361084  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 69.11029052734375 GB
    Memory Allocated: 37.842379570007324  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.42669677734375 GB
    Memory Allocated: 56.61369705200195  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.42669677734375 GB
    Memory Allocated: 56.731496810913086  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.42669677734375 GB
    Memory Allocated: 56.61220932006836  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.42669677734375 GB
    Memory Allocated: 56.57761812210083  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.42669677734375 GB
    Memory Allocated: 56.69541835784912  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 1.1019296646118164  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 22.83199691772461  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 23.295475959777832  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 22.827446937561035  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 22.827446937561035  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 23.406795978546143  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 32.85373878479004  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 32.87131690979004  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 32.85354518890381  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 32.735745429992676  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 32.753324031829834  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

number of input  17844884
----------------------------------------after optimizer
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 1.0412230491638184  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 4.092723369598389
pure train time :  5.336352825164795
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5494022369384766
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0025527477264404297
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.029430389404296875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.552344560623169
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.785655736923218
self.buckets_partition() spend  sec:  2.5818066596984863
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.62982177734375 GB
    Memory Allocated: 1.1389799118041992  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 35.17561054229736  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 36.14065456390381  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 35.168070793151855  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 35.168070793151855  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 36.37437582015991  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 54.29291009902954  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 54.47322225570679  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 54.29077911376953  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 54.27320098876953  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 54.43523645401001  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63177490234375 GB
    Memory Allocated: 1.2713985443115234  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 38.2342734336853  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 39.0836501121521  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 38.22763729095459  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 38.22763729095459  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 39.289358139038086  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 59.22378158569336  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 59.27948713302612  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 59.222424030303955  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 59.042821407318115  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 59.09852743148804  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 1.173384666442871  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 37.57813215255737  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 38.41123914718628  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 37.571500301361084  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 37.571500301361084  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 38.61288404464722  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 58.44715881347656  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 58.495327949523926  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 58.446598529815674  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 58.390183448791504  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 58.438353061676025  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 1.205925464630127  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 37.9055871963501  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 38.7513542175293  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 37.89890766143799  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 37.89890766143799  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 38.956116676330566  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 58.69768285751343  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 58.75307846069336  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 58.697038650512695  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 58.64886951446533  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 58.70426559448242  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 1.2405171394348145  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 37.33903169631958  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 38.170255184173584  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 37.33191394805908  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 37.33191394805908  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 38.370943546295166  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 57.92538070678711  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 57.976706981658936  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 57.92478370666504  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 57.86938810348511  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 57.92071485519409  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63372802734375 GB
    Memory Allocated: 1.2718472480773926  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.24249267578125  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.073822021484375  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.235336780548096  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.235336780548096  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.274498462677  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.68852186203003  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.74057388305664  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.68791627883911  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.636590003967285  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.688642501831055  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.2678585052490234  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.6820855140686  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.4557671546936  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.67604112625122  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.67604112625122  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.64314317703247  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 55.42740869522095  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 55.46199989318848  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 55.427006244659424  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 55.37495422363281  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 55.4095458984375  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.3696866035461426  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.72560501098633  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.64017200469971  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.718459606170654  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.718459606170654  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.86166858673096  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 56.6220383644104  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 56.73983812332153  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 56.62060022354126  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 56.58600902557373  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 56.70380926132202  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.1109356880187988  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 22.862451553344727  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 23.32637310028076  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 22.858827114105225  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 22.858827114105225  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 23.438729286193848  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 32.885669231414795  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 32.903247356414795  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 32.885475635528564  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 32.76767587661743  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 32.78525447845459  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

number of input  17843571
----------------------------------------after optimizer
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.0433101654052734  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.752859592437744
pure train time :  3.1392791271209717
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.635664701461792
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.003328084945678711
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.051844120025634766
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.639585018157959
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.041360139846802
self.buckets_partition() spend  sec:  2.6914618015289307
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.1354703903198242  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.072004318237305  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.03579235076904  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.06447458267212  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.06447458267212  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.26920986175537  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 54.186835289001465  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 54.36714744567871  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 54.18473720550537  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 54.16715908050537  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 54.330403327941895  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.2683749198913574  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.157201290130615  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 39.00552988052368  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.15057325363159  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.15057325363159  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 39.210984230041504  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 59.14317321777344  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 59.1988787651062  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 59.14252519607544  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.96221303939819  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 59.017919063568115  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.1747288703918457  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.65104389190674  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.48629379272461  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.64441204071045  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.64441204071045  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.68847465515137  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.51837682723999  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.56654596328735  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.51752185821533  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.46211099624634  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.51028060913086  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.2065215110778809  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.866328716278076  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.71173906326294  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.85921669006348  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.85921669006348  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.915979862213135  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.656877517700195  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.71227312088013  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.65623331069946  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.60776948928833  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.66316556930542  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.2462496757507324  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.39830303192139  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.231425285339355  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.39123296737671  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.39123296737671  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.43263578414917  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.9866304397583  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 58.03795671463013  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.98603343963623  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.9306378364563  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.98196458816528  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.2747783660888672  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.23579263687134  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.066585063934326  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.228684425354004  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.228684425354004  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 38.26717519760132  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.679656982421875  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.731709003448486  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.67905139923096  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.62772512435913  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 57.680299282073975  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.267960548400879  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.74328327178955  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.517581939697266  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.73723363876343  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.73723363876343  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.70510721206665  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 55.4964804649353  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 55.53107166290283  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 55.49607801437378  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 55.44402599334717  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 55.478617668151855  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.369225025177002  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.76486825942993  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.680471897125244  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.75749635696411  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.75749635696411  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 37.90200090408325  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 56.66138935089111  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 56.779189109802246  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 56.659796714782715  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 56.625205516815186  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 56.74300575256348  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.1100411415100098  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 22.8950138092041  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 23.3587589263916  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 22.891390800476074  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 22.891390800476074  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 23.47107219696045  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 32.917356967926025  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 32.934935092926025  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 32.917163372039795  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 32.79936361312866  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 32.81694221496582  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

number of input  17842906
----------------------------------------after optimizer
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.042588710784912  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.5543298721313477
pure train time :  3.0988662242889404
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.4636571407318115
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0033059120178222656
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.029692649841308594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.4671432971954346
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.83885931968689
self.buckets_partition() spend  sec:  2.496870994567871
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.1378026008605957  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.17913198471069  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.14398908615112  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.17159366607666  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 35.17159366607666  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 36.3776650428772  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 54.29692506790161  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 54.47723722457886  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 54.29401159286499  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 54.27643346786499  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 54.43961143493652  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.63568115234375 GB
    Memory Allocated: 1.273393154144287  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.33214569091797  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 39.18294334411621  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.32549858093262  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.32549858093262  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 39.38899564743042  GigaBytes
Max Memory Allocated: 61.13143539428711  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.314208030700684  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.36991357803345  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.313560009002686  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.13324785232544  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.18895387649536  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1717071533203125  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.5875506401062  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.421066761016846  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.58103847503662  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.58103847503662  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.622933864593506  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.45124816894531  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.499417304992676  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.450687885284424  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.39498233795166  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.44315195083618  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2046465873718262  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.8635835647583  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.70838260650635  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.85698318481445  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.85698318481445  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.91298198699951  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.654643058776855  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.71003866195679  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.65399885177612  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.60582971572876  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.66122579574585  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.240929126739502  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.341269969940186  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.172343730926514  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.334776878356934  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.334776878356934  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.373619079589844  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.927836894989014  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.97916316986084  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.92723989486694  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.87184429168701  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.923171043395996  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2701096534729004  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.15841627120972  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.98778676986694  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.151936531066895  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.151936531066895  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.1890754699707  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.60668420791626  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.65873622894287  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.60607862472534  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.554752349853516  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.60730171203613  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2664885520935059  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.685121059417725  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.45883131027222  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.679076194763184  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.679076194763184  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.6462140083313  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.429696559906006  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.464287757873535  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.42929410934448  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.37724208831787  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.41183376312256  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.366988182067871  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.74872589111328  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.66407489776611  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.74157428741455  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.74157428741455  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.88576078414917  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.644142627716064  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.7619423866272  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.6427001953125  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.60810899734497  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.72590923309326  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1122751235961914  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.88903570175171  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 23.354825496673584  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.884485721588135  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.884485721588135  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 23.46672296524048  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.91430425643921  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.93093967437744  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.91316795349121  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.796310901641846  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.812946796417236  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

number of input  17844305
----------------------------------------after optimizer
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.045961856842041  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.372164487838745
pure train time :  3.1118245124816895
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.750274896621704
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.004026651382446289
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.046369075775146484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.754513740539551
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  7.083789348602295
self.buckets_partition() spend  sec:  2.8009328842163086
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1320886611938477  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.065467834472656  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.02873611450195  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.057941913604736  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.057941913604736  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.26202726364136  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.179712772369385  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.36002492904663  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.177603244781494  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.160025119781494  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.322829246520996  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.272961139678955  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.260085582733154  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 39.10965013504028  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.25344800949097  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.25344800949097  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 39.31540393829346  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.241053104400635  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.2967586517334  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.24040508270264  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.06009292602539  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.11579895019531  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1702914237976074  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.59623718261719  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.43011951446533  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.58972215652466  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.58972215652466  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.63207530975342  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.46209955215454  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.510268688201904  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.46153926849365  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.40583372116089  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.45400333404541  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.205103874206543  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.8814902305603  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.72699785232544  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.874884605407715  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.874884605407715  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.931769371032715  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.67580461502075  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.731200218200684  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.67516040802002  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.626991271972656  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.682387351989746  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2409772872924805  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.337440967559814  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.169424533843994  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.33094072341919  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.33094072341919  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.370920181274414  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.924880504608154  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.97620677947998  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.924283504486084  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.86888790130615  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.92021465301514  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2757072448730469  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.29466962814331  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.1276421546936  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.288161754608154  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.288161754608154  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.3293776512146  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.73799991607666  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.79005193710327  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.73739433288574  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.686068058013916  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.738120555877686  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2655649185180664  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.64020109176636  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.41260004043579  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.6341667175293  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.6341667175293  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.59966564178467  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.38348054885864  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.41807174682617  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.38307809829712  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.33102607727051  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.365617752075195  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.3718342781066895  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.79117155075073  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.70671033859253  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.78401851654053  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.78401851654053  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.92844200134277  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.687424182891846  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.80522394180298  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.68578386306763  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.6511926651001  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.76899290084839  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1140975952148438  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.935574531555176  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 23.400763511657715  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.931443214416504  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.931443214416504  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 23.512929439544678  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.958611488342285  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.976189613342285  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.958417892456055  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.84061813354492  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.85819673538208  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

number of input  17843466
----------------------------------------after optimizer
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.0464024543762207  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.1020543575286865
pure train time :  3.093636989593506
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5870416164398193
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0027005672454833984
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.038314104080200195
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.589937448501587
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.861063241958618
self.buckets_partition() spend  sec:  2.628286838531494
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.134443759918213  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.185123443603516  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.14951229095459  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.17758893966675  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.17758893966675  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.38307523727417  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.3012580871582  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.48157024383545  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.29914951324463  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.28157138824463  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.44472074508667  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2722887992858887  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.27266836166382  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 39.12290334701538  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.26602554321289  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.26602554321289  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 39.328819274902344  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.260265827178955  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.31597137451172  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.25961780548096  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.07930564880371  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.13501167297363  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1709580421447754  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.574824810028076  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.40855646133423  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.56819295883179  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.56819295883179  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.61035776138306  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.44508600234985  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.49325513839722  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.44368314743042  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.3888201713562  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.43698978424072  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2050628662109375  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.83969306945801  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.684715270996094  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.832661628723145  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.832661628723145  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.88893938064575  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.632516860961914  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.687912464141846  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.63187265396118  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.58286094665527  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.63853693008423  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2439236640930176  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.38109493255615  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.21306133270264  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.374595165252686  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.374595165252686  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.41455316543579  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.96951341629028  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.02083969116211  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.96891641616821  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.91352081298828  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.964847564697266  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2757940292358398  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.2777214050293  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.1093053817749  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.27122449874878  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.27122449874878  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.310704708099365  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.71990394592285  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.77195596694946  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.719298362731934  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.66797208786011  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.72042989730835  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2606453895568848  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.608816146850586  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.38105487823486  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.60278272628784  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.60278272628784  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.56808137893677  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.349002838134766  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.383594036102295  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.34860038757324  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.29654836654663  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.33114004135132  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.3693289756774902  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.765485763549805  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.68173122406006  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.75832748413086  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.75832748413086  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.903634548187256  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.663116455078125  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.78091621398926  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.661616802215576  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.62702560424805  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.74482583999634  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.105422019958496  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.84533405303955  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 23.309102058410645  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.841710567474365  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.841710567474365  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 23.421420574188232  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.86672782897949  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.88430595397949  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.86653423309326  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.74873447418213  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.76631307601929  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

number of input  17836160
----------------------------------------after optimizer
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.0379109382629395  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.8688852787017822
pure train time :  3.071737766265869
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5355262756347656
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.003914356231689453
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.029424667358398438
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5396323204040527
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.813989639282227
self.buckets_partition() spend  sec:  2.569098711013794
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1376495361328125  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.1939001083374  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.15927314758301  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.1863579750061  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.1863579750061  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.39307451248169  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.31080198287964  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.491114139556885  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.308321952819824  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.290743827819824  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.453749656677246  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2714190483093262  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.211541175842285  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 39.06130599975586  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.20490217208862  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.20490217208862  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 39.26710844039917  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.200313568115234  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.256019115448  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.199665546417236  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.01935338973999  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.07505941390991  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1734576225280762  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.64483690261841  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.47998666763306  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.63831186294556  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.63831186294556  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.68224906921387  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.51131343841553  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.55948257446289  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.510258197784424  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.455047607421875  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.5032172203064  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2061800956726074  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.9061017036438  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.75193643569946  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.89949321746826  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.89949321746826  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.95678663253784  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.696879863739014  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.752275466918945  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.69623565673828  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.6475715637207  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.70296764373779  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2379961013793945  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.368990421295166  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.19975233078003  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.362499713897705  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.362499713897705  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.40095233917236  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.95536804199219  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.006694316864014  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.95477104187012  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.899375438690186  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.95070219039917  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2708477973937988  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.15751934051514  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.987704277038574  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.15103340148926  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.15103340148926  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.18890905380249  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.60527992248535  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.65733194351196  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.604674339294434  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.55334806442261  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.60632848739624  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2642650604248047  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.70863628387451  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.483144760131836  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.702585220336914  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.702585220336914  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.67072105407715  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.4520468711853  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.48663806915283  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.45164442062378  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.39959239959717  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.434184074401855  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.3647871017456055  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.72104024887085  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.63541078567505  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.71389627456665  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.71389627456665  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.85685968399048  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.61810111999512  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.73590087890625  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.616610050201416  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.58201885223389  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.69981908798218  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.105788230895996  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.82606077194214  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 23.28964376449585  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.82228946685791  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.82228946685791  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 23.40176820755005  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.850666999816895  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.86730241775513  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.8495306968689  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.73267364501953  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.75025224685669  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

number of input  17840397
----------------------------------------after optimizer
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.0383739471435547  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.643756151199341
pure train time :  3.093970775604248
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5849523544311523
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0038945674896240234
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.035590410232543945
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.589043140411377
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.8214991092681885
self.buckets_partition() spend  sec:  2.6246724128723145
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1337494850158691  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.129154682159424  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.09355592727661  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.121620178222656  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.121620178222656  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.32712173461914  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.245670318603516  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.42598247528076  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.24353218078613  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.22595405578613  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.388864517211914  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2704582214355469  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.197641372680664  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 39.0460262298584  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.19101333618164  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.19101333618164  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 39.25149440765381  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.177335262298584  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.23304080963135  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.176687240600586  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.99637508392334  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 59.05208110809326  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1711502075195312  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.60707902908325  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.441479206085205  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.60056018829346  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.60056018829346  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.6435604095459  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.473785400390625  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.52195453643799  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.473225116729736  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.41751956939697  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.465689182281494  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2060279846191406  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.90557861328125  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.751790046691895  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.89889907836914  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.89889907836914  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.956663608551025  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.69466972351074  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.750065326690674  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.69402551651001  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.64585638046265  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.701252460479736  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2420620918273926  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.40290975570679  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.234705448150635  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.39618539810181  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.39618539810181  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.435930252075195  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.99006366729736  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 58.04138994216919  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.98946666717529  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.93407106399536  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.985397815704346  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2755365371704102  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.270546436309814  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.10290575027466  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.26404333114624  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.26404333114624  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 38.304492473602295  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.712085247039795  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.764137268066406  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.71147966384888  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.66015338897705  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 57.71280384063721  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2643895149230957  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.70057153701782  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.47538995742798  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.694518089294434  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.694518089294434  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.66304111480713  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.44477987289429  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.479371070861816  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.444377422332764  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.39232540130615  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 55.42691707611084  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.3624534606933594  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.71226263046265  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.62664842605591  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.70511865615845  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.70511865615845  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 37.8481011390686  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.60867500305176  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.72647476196289  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.606921672821045  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.572330474853516  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 56.69013071060181  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1052374839782715  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.831761360168457  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 23.29494285583496  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.827670574188232  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 22.827670574188232  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 23.40664768218994  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.85369157791138  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.87032699584961  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.85255527496338  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.735698223114014  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 32.75327682495117  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

number of input  17841087
----------------------------------------after optimizer
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.0378074645996094  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.5168538093566895
pure train time :  3.0735158920288086
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5280160903930664
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0029439926147460938
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.03125643730163574
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.531163215637207
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.744372367858887
self.buckets_partition() spend  sec:  2.562458038330078
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.1401939392089844  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.22478246688843  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.19098615646362  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.217233657836914  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 35.217233657836914  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 36.42498826980591  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.34011363983154  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.52042579650879  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.337820053100586  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.320241928100586  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 54.48219442367554  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 77.96966552734375 GB
    Memory Allocated: 1.2760095596313477  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 43.19232177734375 GB
    Memory Allocated: 38.382872104644775  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 44.04388427734375 GB
    Memory Allocated: 39.234434604644775  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 44.04388427734375 GB
    Memory Allocated: 38.3770227432251  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 44.04388427734375 GB
    Memory Allocated: 38.37622547149658  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 44.04388427734375 GB
    Memory Allocated: 39.44047927856445  GigaBytes
Max Memory Allocated: 61.1506085395813  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 63.18060302734375 GB
    Memory Allocated: 59.418484687805176  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 63.18060302734375 GB
    Memory Allocated: 59.47419023513794  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 63.18060302734375 GB
    Memory Allocated: 59.41783666610718  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 63.18060302734375 GB
    Memory Allocated: 59.23752450942993  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 63.18060302734375 GB
    Memory Allocated: 59.29323053359985  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 64.48529052734375 GB
    Memory Allocated: 1.1701679229736328  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 64.48529052734375 GB
    Memory Allocated: 37.61085033416748  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 64.48529052734375 GB
    Memory Allocated: 38.44517517089844  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 64.48529052734375 GB
    Memory Allocated: 37.604331970214844  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 64.48529052734375 GB
    Memory Allocated: 37.604331970214844  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 64.48529052734375 GB
    Memory Allocated: 38.64723825454712  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 58.488638401031494  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 58.53680753707886  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 58.488078117370605  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 58.43237257003784  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 58.48054218292236  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 1.2067461013793945  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 37.91341257095337  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 38.75878095626831  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 37.9068078994751  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 37.9068078994751  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 65.10638427734375 GB
    Memory Allocated: 38.96351861953735  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 58.68565225601196  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 58.741047859191895  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 58.68500804901123  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 58.63683891296387  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 58.69223499298096  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 1.2381057739257812  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 37.33040475845337  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 38.161067485809326  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 37.323915004730225  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 37.323915004730225  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 38.36224365234375  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 57.9182710647583  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 57.96959733963013  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 57.91767406463623  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 57.8622784614563  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 57.91360521316528  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 65.72747802734375 GB
    Memory Allocated: 1.2713313102722168  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 37.19176483154297  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 38.02285575866699  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 37.18500232696533  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 37.18500232696533  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 38.22386598587036  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 57.62717866897583  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 57.67923069000244  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 57.62657308578491  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 57.575246810913086  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 57.627299308776855  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 1.2600746154785156  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 35.5828800201416  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 36.35476589202881  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 35.57684946060181  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 35.57684946060181  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 36.541707038879395  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 55.31106185913086  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 55.34565305709839  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 55.310659408569336  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 55.258607387542725  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 55.29319906234741  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 1.3630995750427246  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 36.67600393295288  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 37.59051465988159  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 36.668859004974365  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 36.668859004974365  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 65.72943115234375 GB
    Memory Allocated: 37.811997413635254  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 73.53607177734375 GB
    Memory Allocated: 56.588218688964844  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 73.53607177734375 GB
    Memory Allocated: 56.70601844787598  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 73.53607177734375 GB
    Memory Allocated: 56.58659648895264  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 73.53607177734375 GB
    Memory Allocated: 56.55200529098511  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 73.53607177734375 GB
    Memory Allocated: 56.6698055267334  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 1.1081109046936035  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 22.83657932281494  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 23.300528526306152  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 22.832022666931152  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 22.832022666931152  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 23.411959171295166  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 32.84336471557617  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 32.86094284057617  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 32.84317111968994  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 32.72537136077881  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 32.74294996261597  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17842991
----------------------------------------after optimizer
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 1.0404877662658691  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.5265090465545654
pure train time :  4.419248104095459
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5236358642578125
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0037572383880615234
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.026581764221191406
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5275657176971436
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.732219219207764
self.buckets_partition() spend  sec:  2.5541791915893555
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 1.1348934173583984  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 35.13141870498657  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 36.09610605239868  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 35.123881816864014  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 35.123881816864014  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 36.32974100112915  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 54.24070501327515  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 54.42101716995239  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 54.2384991645813  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 54.2209210395813  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 54.382965087890625  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 1.2690038681030273  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.200063705444336  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 39.048651695251465  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.19343376159668  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.19343376159668  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 39.25416898727417  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 59.19904565811157  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 59.254751205444336  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 59.198397636413574  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 59.01808547973633  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 59.07379150390625  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 1.1708354949951172  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.64366912841797  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.47821807861328  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.63703727722168  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.63703727722168  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.68022346496582  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.516780853271484  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.56494998931885  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.516220569610596  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.46051502227783  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.50868463516235  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 1.203479290008545  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.93235731124878  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.77844953536987  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.92574691772461  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.92574691772461  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.98336219787598  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.703532218933105  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.75892782211304  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.70288801193237  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.65471887588501  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.7101149559021  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 1.2395882606506348  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.36092185974121  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.1931266784668  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.35442018508911  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.35442018508911  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.394676208496094  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 57.95105028152466  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 58.002376556396484  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 57.95045328140259  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 57.895057678222656  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 57.94638442993164  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 1.2724361419677734  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.193950176239014  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.024672985076904  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.18745994567871  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.18745994567871  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 38.225863456726074  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 57.63073921203613  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 57.682791233062744  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 57.630133628845215  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 57.57880735397339  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 57.63085985183716  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 1.2600293159484863  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 35.67338800430298  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 36.44646406173706  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 35.66734790802002  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 35.66734790802002  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 36.6336932182312  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 55.404014587402344  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 55.43860578536987  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 55.40361213684082  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 55.35156011581421  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 55.3861517906189  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 1.3667287826538086  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 36.774996280670166  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.691197872161865  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 36.76783800125122  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 36.76783800125122  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 74.73919677734375 GB
    Memory Allocated: 37.913090229034424  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.673359870910645  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.79115962982178  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.671814918518066  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.63722372055054  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.75502395629883  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1025099754333496  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.799270629882812  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.262338638305664  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.795652866363525  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.795652866363525  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.37448787689209  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.810028076171875  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.827606201171875  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.809834480285645  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.69203472137451  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.70961332321167  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17835661
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.0362462997436523  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.2965729236602783
pure train time :  3.0866029262542725
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5341038703918457
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.004216670989990234
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.028986692428588867
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5385146141052246
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.759132385253906
self.buckets_partition() spend  sec:  2.5675418376922607
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1352829933166504  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.11174297332764  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.076165199279785  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.10420799255371  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.10420799255371  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.3097357749939  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.21567630767822  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.39598846435547  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.21341323852539  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.19583511352539  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.35789775848389  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.271085262298584  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.20072364807129  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.04997444152832  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.19408845901489  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.19408845901489  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.25565195083618  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.196824073791504  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.25252962112427  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.196176052093506  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.01586389541626  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.07156991958618  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1735587120056152  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.636587619781494  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.471839427948  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.630062103271484  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.630062103271484  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.67412710189819  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.51158905029297  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.55975818634033  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.51102876663208  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.455323219299316  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.50349283218384  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.205155849456787  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.91598987579346  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.761404037475586  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.90931034088135  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.90931034088135  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.96607828140259  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.687599182128906  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.74299478530884  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.686954975128174  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.63878583908081  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.6941819190979  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.23787260055542  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.28942346572876  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.119444370269775  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.28269910812378  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.28269910812378  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.32022523880005  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.881187915802  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.93251419067383  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.88059091567993  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.8251953125  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.876522064208984  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2753429412841797  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.28964948654175  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.12155485153198  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.28315019607544  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.28315019607544  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.32303190231323  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.725533962249756  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.77758598327637  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.72492837905884  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.67360210418701  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.72565460205078  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2630023956298828  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.67274188995361  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.44619655609131  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.666698932647705  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.666698932647705  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.633517265319824  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.40295934677124  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.43755054473877  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.40255689620972  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.350504875183105  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.38509654998779  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.365318775177002  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.73096418380737  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.645902156829834  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.72381591796875  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.72381591796875  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.867488384246826  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.62780952453613  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.745609283447266  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.62612438201904  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.591533184051514  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.709333419799805  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.114393711090088  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.88754177093506  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.351835250854492  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.8830246925354  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.8830246925354  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.46339178085327  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.897804260253906  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.915382385253906  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.897610664367676  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.77981090545654  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.7973895072937  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17842462
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.0481762886047363  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.2369983196258545
pure train time :  3.071948289871216
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.518968105316162
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.002773284912109375
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.026778697967529297
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.522420644760132
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.7295615673065186
self.buckets_partition() spend  sec:  2.549231767654419
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1380023956298828  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.198030948638916  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.1640944480896  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.19048357009888  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.19048357009888  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.39806318283081  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.31236982345581  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.49268198013306  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.310189723968506  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.292611598968506  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.45546340942383  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2694768905639648  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.21311712265015  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.06222581863403  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.206483364105225  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.206483364105225  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.26786947250366  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.21061611175537  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.266321659088135  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.20996809005737  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.02965593338013  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.08536195755005  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1742057800292969  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.675167083740234  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.509958267211914  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.66864490509033  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.66864490509033  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.71213388442993  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.54931116104126  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.59748029708862  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.54875087738037  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.49304533004761  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.54121494293213  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2066683769226074  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.916271686553955  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.76258611679077  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.90965938568115  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.90965938568115  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.96755266189575  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.687217235565186  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.74261283874512  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.68657302856445  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.63840389251709  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.69379997253418  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2419514656066895  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.38552904129028  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.21710538864136  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.379032135009766  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.379032135009766  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.41850280761719  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.97183179855347  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.02315807342529  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.9712347984314  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.915839195251465  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.96716594696045  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2685089111328125  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.13849067687988  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.967132568359375  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.13201665878296  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.13201665878296  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.167819023132324  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.57180643081665  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.62385845184326  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.57120084762573  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.519874572753906  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.571927070617676  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2629070281982422  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.68472623825073  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.45860719680786  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.67867994308472  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.67867994308472  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.64603137969971  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.41983699798584  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.45442819595337  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.419434547424316  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.367382526397705  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.40197420120239  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.3621163368225098  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.644216537475586  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.55742645263672  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.63708162307739  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.63708162307739  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.77859401702881  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.53948354721069  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.657283306121826  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.53794813156128  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.50335693359375  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.62115716934204  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1146836280822754  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.90907049179077  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.374422550201416  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.904613494873047  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.904613494873047  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.48630380630493  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.92152690887451  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.93910503387451  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.92133331298828  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.80353355407715  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.82111215591431  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17845136
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.0497441291809082  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.164565324783325
pure train time :  3.070225238800049
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.516085386276245
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.002752065658569336
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.026428937911987305
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5192174911499023
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.756628751754761
self.buckets_partition() spend  sec:  2.5456783771514893
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1370835304260254  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.17079257965088  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.13569736480713  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.163254261016846  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.163254261016846  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.36938524246216  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.274991512298584  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.45530366897583  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.272886753082275  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.255308628082275  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.41712045669556  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.273031234741211  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.23293113708496  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.08262348175049  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.22629261016846  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.22629261016846  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.288408279418945  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.229384899139404  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.28509044647217  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.228736877441406  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.04842472076416  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.10413074493408  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.171677589416504  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.644184589385986  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.47941255569458  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.6375527381897  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.6375527381897  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.68158769607544  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.51828908920288  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.566458225250244  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.51772880554199  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.46202325820923  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.51019287109375  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2089958190917969  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.99697732925415  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.84412145614624  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.99035882949829  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.99035882949829  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.04928922653198  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.76969766616821  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.825093269348145  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.76905345916748  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.72088432312012  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.77628040313721  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2374892234802246  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.30030965805054  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.13125944137573  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.2938175201416  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.2938175201416  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.332504749298096  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.89235830307007  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.943684577941895  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.891761302948  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.836365699768066  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.88769245147705  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2701616287231445  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.148290157318115  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.977174282073975  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.14181423187256  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.14181423187256  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.17791938781738  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.580358028411865  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.63241004943848  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.57975244522095  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.52842617034912  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.58047866821289  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2663483619689941  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.75314474105835  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.52800226211548  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.7470908164978  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.7470908164978  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.71566295623779  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.48367166519165  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.51826286315918  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.48326921463013  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.431217193603516  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.4658088684082  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.3663601875305176  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.78055000305176  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.695878982543945  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.773398876190186  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.773398876190186  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.91756010055542  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.67772817611694  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.795527935028076  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.676183223724365  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.641592025756836  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.75939226150513  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1051068305969238  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.802719116210938  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.265377044677734  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.7991042137146  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.7991042137146  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.377426624298096  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.81029987335205  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.82787799835205  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.81010627746582  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.69230651855469  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.709885120391846  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17842581
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.0381073951721191  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.03187894821167
pure train time :  3.127983570098877
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5499660968780518
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0032520294189453125
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.025486469268798828
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5534119606018066
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.748615264892578
self.buckets_partition() spend  sec:  2.578951835632324
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1391000747680664  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.18457078933716  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.15009355545044  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.177027225494385  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.177027225494385  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.383930683135986  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.289512157440186  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.46982431411743  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.28718423843384  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.26960611343384  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.43161582946777  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2726397514343262  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.283952713012695  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.13432216644287  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.27730894088745  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.27730894088745  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.34027099609375  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.28120517730713  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.33691072463989  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.28055715560913  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.100244998931885  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.15595102310181  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1714940071105957  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.65009260177612  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.48444604873657  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.643460750579834  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.643460750579834  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.686402797698975  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.523592948913574  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.57176208496094  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.523032665252686  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.46732711791992  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.51549673080444  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.204664707183838  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.85991811752319  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.70472288131714  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.853317737579346  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.853317737579346  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.90932369232178  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.6296067237854  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.68500232696533  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.62896251678467  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.580793380737305  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.636189460754395  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2388200759887695  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.294053077697754  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.12481212615967  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.28756237030029  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.28756237030029  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.326011180877686  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.89064598083496  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.94197225570679  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.89004898071289  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.83465337753296  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.88598012924194  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2763299942016602  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.268831729888916  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.10068368911743  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.26233243942261  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.26233243942261  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.30214738845825  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.70519733428955  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.75724935531616  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.70459175109863  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.65326547622681  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.705317974090576  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2603836059570312  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.610793113708496  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.38276958465576  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.604761600494385  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.604761600494385  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.56973218917847  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.342437744140625  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.377028942108154  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.3420352935791  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.28998327255249  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.32457494735718  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.3676295280456543  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.74873638153076  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.66401958465576  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.74158573150635  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.74158573150635  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.8856897354126  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.646117210388184  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.763916969299316  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.64438724517822  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.60979604721069  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.727596282958984  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1060905456542969  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.847169399261475  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.31102418899536  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.842901706695557  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.842901706695557  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.422720432281494  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.8545937538147  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.8721718788147  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.85440015792847  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.736600399017334  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.75417900085449  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17842756
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.039100170135498  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.96272611618042
pure train time :  3.0695788860321045
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.551569700241089
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.002727985382080078
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.026587247848510742
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.554767370223999
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.668870449066162
self.buckets_partition() spend  sec:  2.58138108253479
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1303200721740723  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.04890823364258  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.011810302734375  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.04138517379761  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.04138517379761  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.24501276016235  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.15202760696411  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.33233976364136  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.14971923828125  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.13214111328125  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.29470348358154  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2684125900268555  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.19571828842163  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.044437885284424  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.18908739089966  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.18908739089966  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.24998712539673  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.191285610198975  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.24699115753174  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.19063758850098  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.01032543182373  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.06603145599365  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.169351577758789  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.578742027282715  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.411662101745605  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.572110176086426  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.572110176086426  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.61326026916504  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.45160102844238  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.499770164489746  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.451040744781494  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.39533519744873  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.44350481033325  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2065997123718262  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.977859020233154  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.82490873336792  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.97124099731445  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.97124099731445  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.03005313873291  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.74991750717163  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.80531311035156  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.7492733001709  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.701104164123535  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.756500244140625  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2412071228027344  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.37304496765137  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.20512771606445  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.366544246673584  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.366544246673584  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.40664768218994  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.96506404876709  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.016390323638916  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.96446704864502  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.90907144546509  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.96039819717407  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2719597816467285  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.22126293182373  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.052175521850586  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.21477127075195  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.21477127075195  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.2534122467041  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.656832695007324  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.708884716033936  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.656227111816406  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.60490083694458  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.65695333480835  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2654919624328613  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.695868492126465  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.4701509475708  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.6898193359375  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.6898193359375  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.65767240524292  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.42885875701904  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.46344995498657  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.42845630645752  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.37640428543091  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.410995960235596  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.3660898208618164  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.72196388244629  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.635727882385254  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.71482467651367  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.71482467651367  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.85702991485596  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.61566686630249  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.73346662521362  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.614229679107666  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.57963848114014  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.69743871688843  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1162776947021484  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.959838390350342  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.42658281326294  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.95552158355713  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.95552158355713  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.538952350616455  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.9718017578125  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.9893798828125  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.97160816192627  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.85380840301514  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.871387004852295  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17844816
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.0507583618164062  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.926279902458191
pure train time :  3.071420907974243
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.52697491645813
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0026786327362060547
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0258638858795166
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.529824733734131
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.790473222732544
self.buckets_partition() spend  sec:  2.5557188987731934
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1337742805480957  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.05395030975342  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.01690101623535  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.04642724990845  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.04642724990845  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.25011587142944  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.1560320854187  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.33634424209595  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.15376329421997  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.13618516921997  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.29900503158569  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2696328163146973  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.24152898788452  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.09125375747681  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.23489046096802  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.23489046096802  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.29704666137695  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.23763608932495  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.293341636657715  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.23698806762695  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.05667591094971  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.11238193511963  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.168384075164795  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.641279220581055  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.47467517852783  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.634647369384766  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.634647369384766  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.676392555236816  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.515252113342285  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.56342124938965  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.5146918296814  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.45898628234863  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.507155895233154  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2010860443115234  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.84134769439697  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.686062812805176  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.83474826812744  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.83474826812744  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.890642166137695  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.610644817352295  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.66604042053223  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.61000061035156  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.5618314743042  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.61722755432129  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2357792854309082  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.306986808776855  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.13767337799072  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.30049705505371  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.30049705505371  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.338855266571045  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.900126934051514  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.95145320892334  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.89952993392944  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.84413433074951  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.895461082458496  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2742862701416016  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.286922454833984  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.11933517456055  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.28041887283325  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.28041887283325  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.320934772491455  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.72264862060547  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.77470064163208  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.72204303741455  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.670716762542725  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.722769260406494  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2603492736816406  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.689473152160645  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.46217918395996  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.683435916900635  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.683435916900635  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.64931869506836  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.41838502883911  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.45297622680664  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.41798257827759  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.36593055725098  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.400522232055664  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.3686509132385254  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.77244853973389  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.688334465026855  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.76529312133789  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.76529312133789  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.9101505279541  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.66963291168213  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.78743267059326  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.66801357269287  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.63342237472534  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.75122261047363  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1104249954223633  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.911128520965576  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.376882076263428  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.907489776611328  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.907489776611328  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.489681720733643  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.92386198043823  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.94144010543823  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.923668384552  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.80586862564087  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.82344722747803  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17839722
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.0449423789978027  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.860921025276184
pure train time :  3.1529204845428467
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.571281909942627
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0029735565185546875
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02561497688293457
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5744452476501465
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.7198591232299805
self.buckets_partition() spend  sec:  2.60010027885437
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1338510513305664  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.07851552963257  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.04196500778198  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.070988178253174  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.070988178253174  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.27530002593994  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.18167972564697  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.36199188232422  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.17941856384277  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.16184043884277  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.324684143066406  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2741336822509766  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.21603536605835  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.06578016281128  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.20939636230469  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.20939636230469  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.27157735824585  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.21258592605591  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.26829147338867  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.21193790435791  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.031625747680664  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.087331771850586  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1684603691101074  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.54577445983887  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.378366470336914  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.53914260864258  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.53914260864258  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.57988262176514  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.432762145996094  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.48093128204346  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.432201862335205  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.37649631500244  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.42466592788696  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2092247009277344  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.95486402511597  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.80115842819214  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.94825220108032  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.94825220108032  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.00612020492554  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.726001262664795  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.78139686584473  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.72535705566406  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.6771879196167  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.73258399963379  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2473554611206055  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.45531463623047  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.28910446166992  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.448800563812256  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.448800563812256  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.49103784561157  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.041199684143066  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.09252595901489  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.040602684020996  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.985207080841064  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.03653383255005  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.272158145904541  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.23877716064453  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.06964302062988  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.23228597640991  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.23228597640991  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.2708683013916  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.6728515625  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.72490358352661  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.67224597930908  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.620919704437256  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.672972202301025  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.265885829925537  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.70482301712036  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.479106426239014  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.6987738609314  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.6987738609314  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.66662836074829  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.437673568725586  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.472264766693115  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.43727111816406  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.38521909713745  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.41981077194214  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.3718342781066895  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.737497329711914  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.65183639526367  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.73035383224487  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.73035383224487  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.87327766418457  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.63283920288086  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.75063896179199  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.63119888305664  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.59660768508911  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.7144079208374  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1176819801330566  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.88957643508911  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.354499340057373  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.885212421417236  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.885212421417236  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.466366291046143  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.900325298309326  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.917903423309326  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.900131702423096  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.78233194351196  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.79991054534912  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17845336
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.0525164604187012  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.8086485862731934
pure train time :  3.069098949432373
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5482566356658936
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.002570629119873047
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.026883363723754883
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.551103353500366
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.732017278671265
self.buckets_partition() spend  sec:  2.5780205726623535
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.137608528137207  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.11797571182251  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.08219575881958  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.11044263839722  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.11044263839722  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.315717697143555  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.2210636138916  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.40137577056885  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.2188982963562  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.2013201713562  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.36379146575928  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2703652381896973  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.231106758117676  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.08032035827637  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.22447204589844  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.22447204589844  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.28598928451538  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.2269024848938  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.28260803222656  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.2262544631958  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.045942306518555  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.10164833068848  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.172464370727539  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.61026859283447  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.44394588470459  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.603755474090576  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.603755474090576  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.64585208892822  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.48310375213623  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.531272888183594  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.48254346847534  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.42683792114258  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.4750075340271  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.205371379852295  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.90151834487915  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.74740171432495  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.89490985870361  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.89490985870361  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.95226430892944  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.673916816711426  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.72931241989136  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.67327260971069  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.62510347366333  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.68049955368042  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2447600364685059  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.339786529541016  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.170902252197266  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.333293437957764  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.333293437957764  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.372188091278076  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.93185567855835  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.983181953430176  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.93125867843628  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.87586307525635  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.92718982696533  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2756690979003906  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.2422833442688  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.073073863983154  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.23579263687134  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.23579263687134  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.27428102493286  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.67719030380249  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.7292423248291  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.67658472061157  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.625258445739746  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.677310943603516  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2693161964416504  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.69471454620361  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.4688777923584  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.688666343688965  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.688666343688965  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.656370639801025  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.427008628845215  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.461599826812744  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.42660617828369  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.37455415725708  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.40914583206177  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.3712825775146484  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.80211162567139  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.717061042785645  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.794963359832764  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.794963359832764  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.938650131225586  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.69993734359741  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.817737102508545  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.69820213317871  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.66361093521118  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.78141117095947  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1106657981872559  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.837078094482422  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.301114082336426  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.832725048065186  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.832725048065186  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.41277027130127  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.84511375427246  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.86269187927246  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.84492015838623  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.7271203994751  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.744699001312256  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17844433
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.044175624847412  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7597887516021729
pure train time :  3.0723938941955566
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5903961658477783
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.0028963088989257812
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02645707130432129
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5935726165771484
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.7842698097229
self.buckets_partition() spend  sec:  2.620060682296753
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1355037689208984  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.120052337646484  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.08441734313965  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.11251783370972  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.11251783370972  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.31797409057617  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.223713397979736  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.40402555465698  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.22154664993286  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.20396852493286  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.36650800704956  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2761931419372559  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.322431564331055  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.17367935180664  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.315781116485596  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.315781116485596  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.37984085083008  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.32066869735718  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.37637424468994  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.32002067565918  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.139708518981934  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.195414543151855  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1730709075927734  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.64056158065796  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.474363803863525  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.63404703140259  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.63404703140259  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.676300048828125  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.51338243484497  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.561551570892334  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.51282215118408  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.45711660385132  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.50528621673584  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2071185111999512  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.87910556793213  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.72412586212158  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.87242603302002  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.87242603302002  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.928701400756836  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.6505389213562  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.70593452453613  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.64989471435547  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.601725578308105  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.657121658325195  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.246816635131836  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.40964889526367  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.24276256561279  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.40292453765869  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.40292453765869  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.44431686401367  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.99998664855957  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.0513129234314  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.9993896484375  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.94399404525757  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.99532079696655  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2751188278198242  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.23186492919922  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.062954902648926  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.22510242462158  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.22510242462158  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.263965129852295  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.66643285751343  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.71848487854004  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.66582727432251  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.614500999450684  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.66655349731445  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2657856941223145  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.663819789886475  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.436556339263916  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.657782554626465  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.657782554626465  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.623703479766846  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.389925479888916  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.424516677856445  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.38952302932739  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.33747100830078  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.37206268310547  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.3669705390930176  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.69327783584595  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.606486797332764  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.686142921447754  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.686142921447754  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.82765436172485  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.587464332580566  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.7052640914917  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.58580303192139  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.55121183395386  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.66901206970215  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1154184341430664  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.891854286193848  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.357221603393555  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.887730598449707  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.887730598449707  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.46943998336792  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.902945041656494  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.920523166656494  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.902751445770264  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.78495168685913  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.80253028869629  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17846354
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.0499343872070312  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7265639305114746
pure train time :  3.0845561027526855
the output layer 
self.num_batch (get_in_degree_bucketing) 9
get_in_degree_bucketing dst global nid length 1207179
len(bkt)  132028
len(bkt)  86214
len(bkt)  63905
len(bkt)  51188
len(bkt)  42783
len(bkt)  37196
len(bkt)  32534
len(bkt)  29230
len(bkt)  25982
len(bkt)  23894
len(bkt)  21638
len(bkt)  19992
len(bkt)  18412
len(bkt)  17082
len(bkt)  15873
len(bkt)  14921
len(bkt)  13503
len(bkt)  12864
len(bkt)  11987
len(bkt)  11400
len(bkt)  10745
len(bkt)  9899
len(bkt)  9352
len(bkt)  8764
len(bkt)  233722
total indegree bucketing result ,  955108
total zero degree bucketing result ,  252071
the number of total output nodes match !!!! 
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  9
type of fanout_dst_nids  <class 'torch.Tensor'>
G_BUCKET_ID_list [[5, 1, 0], [11, 13, 9], [15, 12, 14], [10, 17, 8], [16, 19, 7], [18, 20, 6], [21, 22, 23], [4, 3, 2]]
G_BUCKET_ID_list length 8
backpack scheduling spend  2.5932998657226562
len(g_bucket_nids_list)  8
len(local_split_batches_nid_list)  9
current group_mem  25.125055968761444
current group_mem  36.91317415237427
current group_mem  36.80143466591835
current group_mem  36.13002920150757
current group_mem  35.50618413090706
current group_mem  34.935263872146606
current group_mem  33.60226258635521
current group_mem  29.471689671278
batches output list generation spend  0.00263214111328125
self.weights_list  [0.2331120736858411, 0.07201748870714285, 0.06227411179286585, 0.07161655396589901, 0.06635552805342042, 0.06729407983405941, 0.0447199628224149, 0.152293901732883, 0.021506338330935182]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.030468463897705078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  2.5961203575134277
num_output  955108
self.output_nids  1207179
output nodes length not match !!!!
partition total batch output list spend :  6.823222398757935
self.buckets_partition() spend  sec:  2.6266229152679443
step  0
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1366877555847168  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.14104509353638  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.1059308052063  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.133506774902344  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.133506774902344  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.339613914489746  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.2453498840332  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.42566204071045  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.24325180053711  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.22567367553711  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 54.388957023620605  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  1
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.271660327911377  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.2217698097229  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.07096719741821  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.21513509750366  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.21513509750366  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 39.2766318321228  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.21682834625244  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.272533893585205  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.21618032455444  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.0358681678772  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 59.09157419204712  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  2
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1723790168762207  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.65061378479004  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.48503494262695  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.644094467163086  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.644094467163086  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.68712091445923  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.52532720565796  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.57349634170532  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.52476692199707  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.46906137466431  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.51723098754883  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  3
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.207054615020752  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.93795871734619  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.78410339355469  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.93134784698486  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.93134784698486  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.98902893066406  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.70997858047485  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.765374183654785  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.70933437347412  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.66116523742676  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.71656131744385  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  4
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2465543746948242  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.36052322387695  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.19200611114502  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.354026794433594  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.354026794433594  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.393380641937256  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.951661586761475  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 58.0029878616333  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.951064586639404  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.89566898345947  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.94699573516846  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  5
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.2722563743591309  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.18900537490845  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.019333362579346  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.182518005371094  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.182518005371094  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 38.22042798995972  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.623483180999756  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.67553520202637  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.62287759780884  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.57155132293701  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 57.62360382080078  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  6
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.264021396636963  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.68741464614868  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.4613938331604  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.68136787414551  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 35.68136787414551  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.648841857910156  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.4249153137207  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.45950651168823  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.42451286315918  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.37246084213257  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 55.407052516937256  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  7
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.3683385848999023  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.7599081993103  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.67517805099487  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.75275754928589  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 36.75275754928589  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 37.8968448638916  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.656917572021484  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.77471733093262  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.6552038192749  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.62061262130737  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 56.738412857055664  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

step  8
<class 'torch.Tensor'>
cuda:0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.1117534637451172  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.866503715515137  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.330175399780273  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.861953735351562  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 22.861953735351562  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 23.441543579101562  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------refore rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.875675678253174  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.893253803253174  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.87548208236694  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.75768232345581  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 32.77526092529297  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

number of input  17842080
----------------------------------------after optimizer
 Nvidia-smi: 75.98138427734375 GB
    Memory Allocated: 1.048020839691162  GigaBytes
Max Memory Allocated: 61.25708818435669  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6830205917358398
pure train time :  3.1353037357330322
epoch_time_list  [50.20386862754822, 49.38574576377869, 49.76529407501221, 50.859214067459106, 51.62641644477844, 49.70663285255432, 49.72286128997803, 48.659122705459595, 49.43446922302246, 48.027897357940674, 47.67179083824158, 47.31728768348694, 47.8822135925293, 48.030832290649414, 47.84284281730652, 47.64464044570923, 49.31679177284241, 49.303141593933105, 48.42772579193115, 48.70679044723511]

loading_time list   [0.5768654346466064, 0.6750714778900146, 0.8228724002838135, 0.7818484306335449, 0.9662449359893799, 0.7196083068847656, 0.6943845748901367, 0.6923191547393799, 0.6289052963256836, 0.6343684196472168, 0.6606245040893555, 0.6220262050628662, 0.6535606384277344, 0.6729621887207031, 0.5579016208648682, 0.6064929962158203, 0.697401762008667, 0.5228259563446045, 0.5422041416168213, 0.5463075637817383]

 data loader gen time  40.84018611907959
	---backpack schedule time  [6.848202466964722, 6.8933796882629395, 7.1537024974823, 6.9456400871276855, 7.198511123657227, 6.971763849258423, 6.922009229660034, 6.935364246368408, 6.84978461265564, 6.838831901550293, 6.868585824966431, 6.834879159927368, 6.860087633132935, 6.854525327682495, 6.768095970153809, 6.8933939933776855, 6.8165013790130615, 6.834991931915283, 6.883146524429321, 6.926056623458862]
	---connection_check_time_list  [4.533411264419556, 5.8661887645721436, 5.128460884094238, 5.429187536239624, 6.290639400482178, 5.558484315872192, 5.92934250831604, 5.212063312530518, 4.839370489120483, 4.630218029022217, 4.6215808391571045, 4.627721071243286, 4.6080708503723145, 4.609246730804443, 5.037399768829346, 4.8959972858428955, 5.680636405944824, 5.9031853675842285, 5.533637285232544, 5.55523943901062]
	---block_gen_time_list  [3.977625608444214, 3.9661293029785156, 4.353890419006348, 4.5087456703186035, 4.138479709625244, 4.229300022125244, 4.0938026905059814, 4.052202224731445, 3.948362350463867, 3.98602032661438, 4.021661996841431, 3.8842501640319824, 3.957033157348633, 4.120194435119629, 4.1907737255096436, 3.428150177001953, 4.0904412269592285, 4.146103858947754, 4.120058298110962, 4.194246292114258]
training time  [10.17829442024231, 7.409236669540405, 7.346540451049805, 7.74431586265564, 7.513826847076416, 7.416031122207642, 7.326681852340698, 7.187964200973511, 8.5880446434021, 7.048936128616333, 7.06381893157959, 6.987244606018066, 7.305994749069214, 7.131964921951294, 7.113033056259155, 7.395555257797241, 7.119049549102783, 7.2425456047058105, 7.1900954246521, 7.315727233886719]
---feature block loading time  [4.8302953243255615, 4.077819347381592, 4.053905725479126, 4.438011407852173, 4.226017475128174, 4.152216911315918, 4.040601968765259, 3.92124080657959, 3.9781432151794434, 3.771103620529175, 3.799210548400879, 3.7244527339935303, 3.9849252700805664, 3.868781089782715, 3.8479089736938477, 4.046373605728149, 3.857255220413208, 3.9655709266662598, 3.911198377609253, 3.9856014251708984]


epoch_time avg   48.70759107172489
loading_time avg   0.6511336416006088
 data loader gen time avg 40.74287839233875
	---backpack schedule time avg 6.891033083200455
	---connection_check_time avg  5.220802068710327
	---block_gen_time avg  4.037567541003227
training time  7.309157133102417
---feature block loading time  3.942537635564804
pure train time per /epoch  [5.336352825164795, 3.1392791271209717, 3.0988662242889404, 3.1118245124816895, 3.093636989593506, 3.071737766265869, 3.093970775604248, 3.0735158920288086, 4.419248104095459, 3.0866029262542725, 3.071948289871216, 3.070225238800049, 3.127983570098877, 3.0695788860321045, 3.071420907974243, 3.1529204845428467, 3.069098949432373, 3.0723938941955566, 3.0845561027526855, 3.1353037357330322]
pure train time average  3.1691745309268726
num_input list  [17844884, 17843571, 17842906, 17844305, 17843466, 17836160, 17840397, 17841087, 17842991, 17835661, 17842462, 17845136, 17842581, 17842756, 17844816, 17839722, 17845336, 17844433, 17846354, 17842080]
num_input  average  17842555.2
